{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4260,"status":"ok","timestamp":1734004929197,"user":{"displayName":"seonghoon oh","userId":"01050507775812942445"},"user_tz":-540},"id":"iMCo_igKapAi","outputId":"2a988d13-bf5a-467b-e992-a715249d1b04"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1734004929197,"user":{"displayName":"seonghoon oh","userId":"01050507775812942445"},"user_tz":-540},"id":"P8XXyOyRzaWl","outputId":"ab22ea77-eb0a-4cd9-f58b-0e424cfc20e1"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/2024/dl2\n"]}],"source":["%cd /content/drive/MyDrive/2024/dl2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":454,"status":"ok","timestamp":1733497732350,"user":{"displayName":"seonghoon oh","userId":"01050507775812942445"},"user_tz":-540},"id":"W83XdrHozd7z","outputId":"c64853ae-93e5-433d-a4ef-8afd111aa684"},"outputs":[{"name":"stdout","output_type":"stream","text":["Reinitialized existing Git repository in /content/drive/MyDrive/2024/dl2/.git/\n"]}],"source":["!git init"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hEIU2dgCz97E"},"outputs":[],"source":["!git remote add source https://github.com/ssuai/deep_learning_from_scratch2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7392,"status":"ok","timestamp":1733488473746,"user":{"displayName":"seonghoon oh","userId":"01050507775812942445"},"user_tz":-540},"id":"jbsMkyhtzfdM","outputId":"695f7440-a826-460a-ed03-36e408e1588d"},"outputs":[{"name":"stdout","output_type":"stream","text":["remote: Enumerating objects: 668, done.\u001b[K\n","remote: Counting objects:   0% (1/366)\u001b[K\rremote: Counting objects:   1% (4/366)\u001b[K\rremote: Counting objects:   2% (8/366)\u001b[K\rremote: Counting objects:   3% (11/366)\u001b[K\rremote: Counting objects:   4% (15/366)\u001b[K\rremote: Counting objects:   5% (19/366)\u001b[K\rremote: Counting objects:   6% (22/366)\u001b[K\rremote: Counting objects:   7% (26/366)\u001b[K\rremote: Counting objects:   8% (30/366)\u001b[K\rremote: Counting objects:   9% (33/366)\u001b[K\rremote: Counting objects:  10% (37/366)\u001b[K\rremote: Counting objects:  11% (41/366)\u001b[K\rremote: Counting objects:  12% (44/366)\u001b[K\rremote: Counting objects:  13% (48/366)\u001b[K\rremote: Counting objects:  14% (52/366)\u001b[K\rremote: Counting objects:  15% (55/366)\u001b[K\rremote: Counting objects:  16% (59/366)\u001b[K\rremote: Counting objects:  17% (63/366)\u001b[K\rremote: Counting objects:  18% (66/366)\u001b[K\rremote: Counting objects:  19% (70/366)\u001b[K\rremote: Counting objects:  20% (74/366)\u001b[K\rremote: Counting objects:  21% (77/366)\u001b[K\rremote: Counting objects:  22% (81/366)\u001b[K\rremote: Counting objects:  23% (85/366)\u001b[K\rremote: Counting objects:  24% (88/366)\u001b[K\rremote: Counting objects:  25% (92/366)\u001b[K\rremote: Counting objects:  26% (96/366)\u001b[K\rremote: Counting objects:  27% (99/366)\u001b[K\rremote: Counting objects:  28% (103/366)\u001b[K\rremote: Counting objects:  29% (107/366)\u001b[K\rremote: Counting objects:  30% (110/366)\u001b[K\rremote: Counting objects:  31% (114/366)\u001b[K\rremote: Counting objects:  32% (118/366)\u001b[K\rremote: Counting objects:  33% (121/366)\u001b[K\rremote: Counting objects:  34% (125/366)\u001b[K\rremote: Counting objects:  35% (129/366)\u001b[K\rremote: Counting objects:  36% (132/366)\u001b[K\rremote: Counting objects:  37% (136/366)\u001b[K\rremote: Counting objects:  38% (140/366)\u001b[K\rremote: Counting objects:  39% (143/366)\u001b[K\rremote: Counting objects:  40% (147/366)\u001b[K\rremote: Counting objects:  41% (151/366)\u001b[K\rremote: Counting objects:  42% (154/366)\u001b[K\rremote: Counting objects:  43% (158/366)\u001b[K\rremote: Counting objects:  44% (162/366)\u001b[K\rremote: Counting objects:  45% (165/366)\u001b[K\rremote: Counting objects:  46% (169/366)\u001b[K\rremote: Counting objects:  47% (173/366)\u001b[K\rremote: Counting objects:  48% (176/366)\u001b[K\rremote: Counting objects:  49% (180/366)\u001b[K\rremote: Counting objects:  50% (183/366)\u001b[K\rremote: Counting objects:  51% (187/366)\u001b[K\rremote: Counting objects:  52% (191/366)\u001b[K\rremote: Counting objects:  53% (194/366)\u001b[K\rremote: Counting objects:  54% (198/366)\u001b[K\rremote: Counting objects:  55% (202/366)\u001b[K\rremote: Counting objects:  56% (205/366)\u001b[K\rremote: Counting objects:  57% (209/366)\u001b[K\rremote: Counting objects:  58% (213/366)\u001b[K\rremote: Counting objects:  59% (216/366)\u001b[K\rremote: Counting objects:  60% (220/366)\u001b[K\rremote: Counting objects:  61% (224/366)\u001b[K\rremote: Counting objects:  62% (227/366)\u001b[K\rremote: Counting objects:  63% (231/366)\u001b[K\rremote: Counting objects:  64% (235/366)\u001b[K\rremote: Counting objects:  65% (238/366)\u001b[K\rremote: Counting objects:  66% (242/366)\u001b[K\rremote: Counting objects:  67% (246/366)\u001b[K\rremote: Counting objects:  68% (249/366)\u001b[K\rremote: Counting objects:  69% (253/366)\u001b[K\rremote: Counting objects:  70% (257/366)\u001b[K\rremote: Counting objects:  71% (260/366)\u001b[K\rremote: Counting objects:  72% (264/366)\u001b[K\rremote: Counting objects:  73% (268/366)\u001b[K\rremote: Counting objects:  74% (271/366)\u001b[K\rremote: Counting objects:  75% (275/366)\u001b[K\rremote: Counting objects:  76% (279/366)\u001b[K\rremote: Counting objects:  77% (282/366)\u001b[K\rremote: Counting objects:  78% (286/366)\u001b[K\rremote: Counting objects:  79% (290/366)\u001b[K\rremote: Counting objects:  80% (293/366)\u001b[K\rremote: Counting objects:  81% (297/366)\u001b[K\rremote: Counting objects:  82% (301/366)\u001b[K\rremote: Counting objects:  83% (304/366)\u001b[K\rremote: Counting objects:  84% (308/366)\u001b[K\rremote: Counting objects:  85% (312/366)\u001b[K\rremote: Counting objects:  86% (315/366)\u001b[K\rremote: Counting objects:  87% (319/366)\u001b[K\rremote: Counting objects:  88% (323/366)\u001b[K\rremote: Counting objects:  89% (326/366)\u001b[K\rremote: Counting objects:  90% (330/366)\u001b[K\rremote: Counting objects:  91% (334/366)\u001b[K\rremote: Counting objects:  92% (337/366)\u001b[K\rremote: Counting objects:  93% (341/366)\u001b[K\rremote: Counting objects:  94% (345/366)\u001b[K\rremote: Counting objects:  95% (348/366)\u001b[K\rremote: Counting objects:  96% (352/366)\u001b[K\rremote: Counting objects:  97% (356/366)\u001b[K\rremote: Counting objects:  98% (359/366)\u001b[K\rremote: Counting objects:  99% (363/366)\u001b[K\rremote: Counting objects: 100% (366/366)\u001b[K\rremote: Counting objects: 100% (366/366), done.\u001b[K\n","remote: Compressing objects: 100% (98/98), done.\u001b[K\n","remote: Total 668 (delta 287), reused 298 (delta 266), pack-reused 302 (from 1)\u001b[K\n","Receiving objects: 100% (668/668), 31.14 MiB | 16.70 MiB/s, done.\n","Resolving deltas: 100% (400/400), done.\n","From https://github.com/ssuai/deep_learning_from_scratch2\n"," * [new branch]      master     -\u003e source/master\n","From https://github.com/ssuai/deep_learning_from_scratch2\n"," * branch            master     -\u003e FETCH_HEAD\n"]}],"source":["!git sparse-checkout init --cone\n","!git sparse-checkout set common dataset ch06 ch07 ch08\n","!git fetch source\n","!git pull source master"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":447,"status":"ok","timestamp":1733496302508,"user":{"displayName":"seonghoon oh","userId":"01050507775812942445"},"user_tz":-540},"id":"d8c1zSxu3tWU","outputId":"2b44c41e-b14e-4c21-ad49-f62695e95b6e"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/2024/dl2/ch06\n"]}],"source":["%cd ch06"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3515,"status":"ok","timestamp":1734005680720,"user":{"displayName":"seonghoon oh","userId":"01050507775812942445"},"user_tz":-540},"id":"wYSBYGtYE5mY","outputId":"fd53448c-1c87-4dc6-ad5c-1f4b24da77ab"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: colab_ssh in /usr/local/lib/python3.10/dist-packages (0.3.27)\n"]}],"source":["import locale\n","locale.getpreferredencoding = lambda: \"UTF-8\"\n","!pip install colab_ssh --upgrade"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true},"id":"v3imSbhwE-Ff"},"outputs":[{"ename":"UnicodeDecodeError","evalue":"'ascii' codec can't decode byte 0xe2 in position 935: ordinal not in range(128)","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-13-b3e5a1195c0c\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 3\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcolab_ssh\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlaunch_ssh_cloudflared\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_git_cloudflared\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rm cloudflared'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 3\u001b[0;31m \u001b[0mlaunch_ssh_cloudflared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'squid2squid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/colab_ssh/launch_ssh_cloudflared.py\u001b[0m in \u001b[0;36mlaunch_ssh_cloudflared\u001b[0;34m(password, verbose, prevent_interrupt, kill_other_processes)\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"IPython\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'ipykernel'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mHTML\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 99\u001b[0;31m             \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHTML\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrender_template\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"launch_ssh_cloudflared.html\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Now, you need to setup your client machine by following these steps:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/colab_ssh/utils/ui/render_html.py\u001b[0m in \u001b[0;36mrender_template\u001b[0;34m(filename, params)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrender_template\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{Path(__file__).resolve().parent}/{filename}\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 5\u001b[0;31m                 \u001b[0mtemplate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mtemplate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/encodings/ascii.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 26\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascii_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xe2 in position 935: ordinal not in range(128)"]}],"source":["from colab_ssh import launch_ssh_cloudflared, init_git_cloudflared\n","!rm cloudflared\n","launch_ssh_cloudflared(password='squid2squid')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2580797,"status":"ok","timestamp":1733491489676,"user":{"displayName":"seonghoon oh","userId":"01050507775812942445"},"user_tz":-540},"id":"M9bbNMDQ0WM_","outputId":"50af26ac-401f-4ce9-c547-8f2081013bbc"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[92m------------------------------------------------------------\u001b[0m\n","                       \u001b[92mGPU Mode (cupy)\u001b[0m\n","\u001b[92m------------------------------------------------------------\u001b[0m\n","\n","Downloading ptb.train.txt ... \n","Done\n","Downloading ptb.valid.txt ... \n","Done\n","Downloading ptb.test.txt ... \n","Done\n","| 에폭 1 |  반복 1 / 1327 | 시간 22[s] | 퍼플렉서티 10000.44\n","| 에폭 1 |  반복 21 / 1327 | 시간 26[s] | 퍼플렉서티 3926.44\n","| 에폭 1 |  반복 41 / 1327 | 시간 29[s] | 퍼플렉서티 1711.63\n","| 에폭 1 |  반복 61 / 1327 | 시간 33[s] | 퍼플렉서티 1289.45\n","| 에폭 1 |  반복 81 / 1327 | 시간 38[s] | 퍼플렉서티 1063.47\n","| 에폭 1 |  반복 101 / 1327 | 시간 41[s] | 퍼플렉서티 873.25\n","| 에폭 1 |  반복 121 / 1327 | 시간 45[s] | 퍼플렉서티 811.72\n","| 에폭 1 |  반복 141 / 1327 | 시간 50[s] | 퍼플렉서티 700.63\n","| 에폭 1 |  반복 161 / 1327 | 시간 53[s] | 퍼플렉서티 671.81\n","| 에폭 1 |  반복 181 / 1327 | 시간 57[s] | 퍼플렉서티 697.71\n","| 에폭 1 |  반복 201 / 1327 | 시간 60[s] | 퍼플렉서티 586.85\n","| 에폭 1 |  반복 221 / 1327 | 시간 64[s] | 퍼플렉서티 577.19\n","| 에폭 1 |  반복 241 / 1327 | 시간 68[s] | 퍼플렉서티 508.95\n","| 에폭 1 |  반복 261 / 1327 | 시간 72[s] | 퍼플렉서티 545.44\n","| 에폭 1 |  반복 281 / 1327 | 시간 75[s] | 퍼플렉서티 522.49\n","| 에폭 1 |  반복 301 / 1327 | 시간 80[s] | 퍼플렉서티 447.87\n","| 에폭 1 |  반복 321 / 1327 | 시간 83[s] | 퍼플렉서티 389.10\n","| 에폭 1 |  반복 341 / 1327 | 시간 87[s] | 퍼플렉서티 449.13\n","| 에폭 1 |  반복 361 / 1327 | 시간 91[s] | 퍼플렉서티 463.91\n","| 에폭 1 |  반복 381 / 1327 | 시간 95[s] | 퍼플렉서티 383.49\n","| 에폭 1 |  반복 401 / 1327 | 시간 98[s] | 퍼플렉서티 408.37\n","| 에폭 1 |  반복 421 / 1327 | 시간 101[s] | 퍼플렉서티 395.06\n","| 에폭 1 |  반복 441 / 1327 | 시간 105[s] | 퍼플렉서티 374.71\n","| 에폭 1 |  반복 461 / 1327 | 시간 108[s] | 퍼플렉서티 369.50\n","| 에폭 1 |  반복 481 / 1327 | 시간 111[s] | 퍼플렉서티 346.05\n","| 에폭 1 |  반복 501 / 1327 | 시간 115[s] | 퍼플렉서티 354.22\n","| 에폭 1 |  반복 521 / 1327 | 시간 118[s] | 퍼플렉서티 338.59\n","| 에폭 1 |  반복 541 / 1327 | 시간 122[s] | 퍼플렉서티 364.43\n","| 에폭 1 |  반복 561 / 1327 | 시간 125[s] | 퍼플렉서티 321.26\n","| 에폭 1 |  반복 581 / 1327 | 시간 128[s] | 퍼플렉서티 292.11\n","| 에폭 1 |  반복 601 / 1327 | 시간 131[s] | 퍼플렉서티 378.02\n","| 에폭 1 |  반복 621 / 1327 | 시간 136[s] | 퍼플렉서티 349.72\n","| 에폭 1 |  반복 641 / 1327 | 시간 139[s] | 퍼플렉서티 313.18\n","| 에폭 1 |  반복 661 / 1327 | 시간 142[s] | 퍼플렉서티 299.62\n","| 에폭 1 |  반복 681 / 1327 | 시간 145[s] | 퍼플렉서티 256.33\n","| 에폭 1 |  반복 701 / 1327 | 시간 149[s] | 퍼플렉서티 279.38\n","| 에폭 1 |  반복 721 / 1327 | 시간 152[s] | 퍼플렉서티 285.69\n","| 에폭 1 |  반복 741 / 1327 | 시간 155[s] | 퍼플렉서티 244.10\n","| 에폭 1 |  반복 761 / 1327 | 시간 158[s] | 퍼플렉서티 260.23\n","| 에폭 1 |  반복 781 / 1327 | 시간 163[s] | 퍼플렉서티 241.43\n","| 에폭 1 |  반복 801 / 1327 | 시간 166[s] | 퍼플렉서티 267.96\n","| 에폭 1 |  반복 821 / 1327 | 시간 169[s] | 퍼플렉서티 249.91\n","| 에폭 1 |  반복 841 / 1327 | 시간 172[s] | 퍼플렉서티 252.81\n","| 에폭 1 |  반복 861 / 1327 | 시간 176[s] | 퍼플렉서티 249.84\n","| 에폭 1 |  반복 881 / 1327 | 시간 179[s] | 퍼플렉서티 232.24\n","| 에폭 1 |  반복 901 / 1327 | 시간 182[s] | 퍼플렉서티 282.64\n","| 에폭 1 |  반복 921 / 1327 | 시간 185[s] | 퍼플렉서티 256.26\n","| 에폭 1 |  반복 941 / 1327 | 시간 189[s] | 퍼플렉서티 253.71\n","| 에폭 1 |  반복 961 / 1327 | 시간 193[s] | 퍼플렉서티 274.66\n","| 에폭 1 |  반복 981 / 1327 | 시간 196[s] | 퍼플렉서티 255.37\n","| 에폭 1 |  반복 1001 / 1327 | 시간 199[s] | 퍼플렉서티 216.39\n","| 에폭 1 |  반복 1021 / 1327 | 시간 203[s] | 퍼플렉서티 252.37\n","| 에폭 1 |  반복 1041 / 1327 | 시간 206[s] | 퍼플렉서티 230.34\n","| 에폭 1 |  반복 1061 / 1327 | 시간 209[s] | 퍼플렉서티 217.50\n","| 에폭 1 |  반복 1081 / 1327 | 시간 212[s] | 퍼플렉서티 189.53\n","| 에폭 1 |  반복 1101 / 1327 | 시간 216[s] | 퍼플렉서티 213.44\n","| 에폭 1 |  반복 1121 / 1327 | 시간 220[s] | 퍼플렉서티 256.65\n","| 에폭 1 |  반복 1141 / 1327 | 시간 223[s] | 퍼플렉서티 231.03\n","| 에폭 1 |  반복 1161 / 1327 | 시간 226[s] | 퍼플렉서티 219.88\n","| 에폭 1 |  반복 1181 / 1327 | 시간 230[s] | 퍼플렉서티 210.14\n","| 에폭 1 |  반복 1201 / 1327 | 시간 233[s] | 퍼플렉서티 180.77\n","| 에폭 1 |  반복 1221 / 1327 | 시간 236[s] | 퍼플렉서티 177.83\n","| 에폭 1 |  반복 1241 / 1327 | 시간 239[s] | 퍼플렉서티 207.72\n","| 에폭 1 |  반복 1261 / 1327 | 시간 243[s] | 퍼플렉서티 190.93\n","| 에폭 1 |  반복 1281 / 1327 | 시간 247[s] | 퍼플렉서티 199.94\n","| 에폭 1 |  반복 1301 / 1327 | 시간 250[s] | 퍼플렉서티 246.48\n","| 에폭 1 |  반복 1321 / 1327 | 시간 253[s] | 퍼플렉서티 233.39\n","퍼플렉서티 평가 중 ...\n","209 / 210\n","검증 퍼플렉서티:  197.4835\n","--------------------------------------------------\n","| 에폭 2 |  반복 1 / 1327 | 시간 0[s] | 퍼플렉서티 280.72\n","| 에폭 2 |  반복 21 / 1327 | 시간 3[s] | 퍼플렉서티 227.55\n","| 에폭 2 |  반복 41 / 1327 | 시간 6[s] | 퍼플렉서티 213.83\n","| 에폭 2 |  반복 61 / 1327 | 시간 10[s] | 퍼플렉서티 194.30\n","| 에폭 2 |  반복 81 / 1327 | 시간 14[s] | 퍼플렉서티 177.78\n","| 에폭 2 |  반복 101 / 1327 | 시간 17[s] | 퍼플렉서티 167.31\n","| 에폭 2 |  반복 121 / 1327 | 시간 20[s] | 퍼플렉서티 180.41\n","| 에폭 2 |  반복 141 / 1327 | 시간 23[s] | 퍼플렉서티 200.34\n","| 에폭 2 |  반복 161 / 1327 | 시간 27[s] | 퍼플렉서티 216.78\n","| 에폭 2 |  반복 181 / 1327 | 시간 31[s] | 퍼플렉서티 224.04\n","| 에폭 2 |  반복 201 / 1327 | 시간 34[s] | 퍼플렉서티 207.61\n","| 에폭 2 |  반복 221 / 1327 | 시간 37[s] | 퍼플렉서티 203.87\n","| 에폭 2 |  반복 241 / 1327 | 시간 40[s] | 퍼플렉서티 196.54\n","| 에폭 2 |  반복 261 / 1327 | 시간 44[s] | 퍼플렉서티 212.70\n","| 에폭 2 |  반복 281 / 1327 | 시간 47[s] | 퍼플렉서티 205.56\n","| 에폭 2 |  반복 301 / 1327 | 시간 50[s] | 퍼플렉서티 184.17\n","| 에폭 2 |  반복 321 / 1327 | 시간 54[s] | 퍼플렉서티 154.26\n","| 에폭 2 |  반복 341 / 1327 | 시간 58[s] | 퍼플렉서티 200.30\n","| 에폭 2 |  반복 361 / 1327 | 시간 61[s] | 퍼플렉서티 216.19\n","| 에폭 2 |  반복 381 / 1327 | 시간 64[s] | 퍼플렉서티 171.28\n","| 에폭 2 |  반복 401 / 1327 | 시간 67[s] | 퍼플렉서티 191.97\n","| 에폭 2 |  반복 421 / 1327 | 시간 71[s] | 퍼플렉서티 176.36\n","| 에폭 2 |  반복 441 / 1327 | 시간 74[s] | 퍼플렉서티 180.35\n","| 에폭 2 |  반복 461 / 1327 | 시간 77[s] | 퍼플렉서티 183.03\n","| 에폭 2 |  반복 481 / 1327 | 시간 81[s] | 퍼플렉서티 175.08\n","| 에폭 2 |  반복 501 / 1327 | 시간 85[s] | 퍼플렉서티 190.63\n","| 에폭 2 |  반복 521 / 1327 | 시간 88[s] | 퍼플렉서티 190.31\n","| 에폭 2 |  반복 541 / 1327 | 시간 91[s] | 퍼플렉서티 200.49\n","| 에폭 2 |  반복 561 / 1327 | 시간 94[s] | 퍼플렉서티 173.43\n","| 에폭 2 |  반복 581 / 1327 | 시간 98[s] | 퍼플렉서티 156.34\n","| 에폭 2 |  반복 601 / 1327 | 시간 101[s] | 퍼플렉서티 214.83\n","| 에폭 2 |  반복 621 / 1327 | 시간 104[s] | 퍼플렉서티 202.85\n","| 에폭 2 |  반복 641 / 1327 | 시간 108[s] | 퍼플렉서티 182.85\n","| 에폭 2 |  반복 661 / 1327 | 시간 112[s] | 퍼플렉서티 173.07\n","| 에폭 2 |  반복 681 / 1327 | 시간 115[s] | 퍼플렉서티 147.70\n","| 에폭 2 |  반복 701 / 1327 | 시간 118[s] | 퍼플렉서티 169.06\n","| 에폭 2 |  반복 721 / 1327 | 시간 121[s] | 퍼플렉서티 174.79\n","| 에폭 2 |  반복 741 / 1327 | 시간 125[s] | 퍼플렉서티 151.01\n","| 에폭 2 |  반복 761 / 1327 | 시간 128[s] | 퍼플렉서티 149.99\n","| 에폭 2 |  반복 781 / 1327 | 시간 131[s] | 퍼플렉서티 148.56\n","| 에폭 2 |  반복 801 / 1327 | 시간 134[s] | 퍼플렉서티 168.70\n","| 에폭 2 |  반복 821 / 1327 | 시간 139[s] | 퍼플렉서티 160.80\n","| 에폭 2 |  반복 841 / 1327 | 시간 142[s] | 퍼플렉서티 165.96\n","| 에폭 2 |  반복 861 / 1327 | 시간 145[s] | 퍼플렉서티 161.36\n","| 에폭 2 |  반복 881 / 1327 | 시간 148[s] | 퍼플렉서티 149.51\n","| 에폭 2 |  반복 901 / 1327 | 시간 153[s] | 퍼플렉서티 188.17\n","| 에폭 2 |  반복 921 / 1327 | 시간 156[s] | 퍼플렉서티 164.81\n","| 에폭 2 |  반복 941 / 1327 | 시간 159[s] | 퍼플렉서티 170.83\n","| 에폭 2 |  반복 961 / 1327 | 시간 162[s] | 퍼플렉서티 185.96\n","| 에폭 2 |  반복 981 / 1327 | 시간 166[s] | 퍼플렉서티 173.99\n","| 에폭 2 |  반복 1001 / 1327 | 시간 169[s] | 퍼플렉서티 146.58\n","| 에폭 2 |  반복 1021 / 1327 | 시간 173[s] | 퍼플렉서티 176.98\n","| 에폭 2 |  반복 1041 / 1327 | 시간 176[s] | 퍼플렉서티 158.39\n","| 에폭 2 |  반복 1061 / 1327 | 시간 180[s] | 퍼플렉서티 147.62\n","| 에폭 2 |  반복 1081 / 1327 | 시간 183[s] | 퍼플렉서티 124.26\n","| 에폭 2 |  반복 1101 / 1327 | 시간 186[s] | 퍼플렉서티 135.05\n","| 에폭 2 |  반복 1121 / 1327 | 시간 190[s] | 퍼플렉서티 171.63\n","| 에폭 2 |  반복 1141 / 1327 | 시간 194[s] | 퍼플렉서티 163.41\n","| 에폭 2 |  반복 1161 / 1327 | 시간 197[s] | 퍼플렉서티 147.68\n","| 에폭 2 |  반복 1181 / 1327 | 시간 200[s] | 퍼플렉서티 147.04\n","| 에폭 2 |  반복 1201 / 1327 | 시간 203[s] | 퍼플렉서티 127.53\n","| 에폭 2 |  반복 1221 / 1327 | 시간 207[s] | 퍼플렉서티 125.07\n","| 에폭 2 |  반복 1241 / 1327 | 시간 210[s] | 퍼플렉서티 145.93\n","| 에폭 2 |  반복 1261 / 1327 | 시간 213[s] | 퍼플렉서티 138.02\n","| 에폭 2 |  반복 1281 / 1327 | 시간 217[s] | 퍼플렉서티 140.05\n","| 에폭 2 |  반복 1301 / 1327 | 시간 221[s] | 퍼플렉서티 176.37\n","| 에폭 2 |  반복 1321 / 1327 | 시간 224[s] | 퍼플렉서티 171.43\n","퍼플렉서티 평가 중 ...\n","209 / 210\n","검증 퍼플렉서티:  145.57785\n","--------------------------------------------------\n","| 에폭 3 |  반복 1 / 1327 | 시간 0[s] | 퍼플렉서티 219.06\n","| 에폭 3 |  반복 21 / 1327 | 시간 3[s] | 퍼플렉서티 160.55\n","| 에폭 3 |  반복 41 / 1327 | 시간 7[s] | 퍼플렉서티 151.88\n","| 에폭 3 |  반복 61 / 1327 | 시간 10[s] | 퍼플렉서티 142.04\n","| 에폭 3 |  반복 81 / 1327 | 시간 14[s] | 퍼플렉서티 126.74\n","| 에폭 3 |  반복 101 / 1327 | 시간 17[s] | 퍼플렉서티 120.71\n","| 에폭 3 |  반복 121 / 1327 | 시간 21[s] | 퍼플렉서티 134.34\n","| 에폭 3 |  반복 141 / 1327 | 시간 24[s] | 퍼플렉서티 146.42\n","| 에폭 3 |  반복 161 / 1327 | 시간 27[s] | 퍼플렉서티 161.58\n","| 에폭 3 |  반복 181 / 1327 | 시간 30[s] | 퍼플렉서티 169.05\n","| 에폭 3 |  반복 201 / 1327 | 시간 34[s] | 퍼플렉서티 158.11\n","| 에폭 3 |  반복 221 / 1327 | 시간 38[s] | 퍼플렉서티 155.50\n","| 에폭 3 |  반복 241 / 1327 | 시간 41[s] | 퍼플렉서티 150.31\n","| 에폭 3 |  반복 261 / 1327 | 시간 44[s] | 퍼플렉서티 161.70\n","| 에폭 3 |  반복 281 / 1327 | 시간 48[s] | 퍼플렉서티 157.17\n","| 에폭 3 |  반복 301 / 1327 | 시간 51[s] | 퍼플렉서티 138.70\n","| 에폭 3 |  반복 321 / 1327 | 시간 54[s] | 퍼플렉서티 110.65\n","| 에폭 3 |  반복 341 / 1327 | 시간 58[s] | 퍼플렉서티 150.63\n","| 에폭 3 |  반복 361 / 1327 | 시간 61[s] | 퍼플렉서티 163.95\n","| 에폭 3 |  반복 381 / 1327 | 시간 65[s] | 퍼플렉서티 129.98\n","| 에폭 3 |  반복 401 / 1327 | 시간 68[s] | 퍼플렉서티 148.40\n","| 에폭 3 |  반복 421 / 1327 | 시간 71[s] | 퍼플렉서티 131.08\n","| 에폭 3 |  반복 441 / 1327 | 시간 75[s] | 퍼플렉서티 139.68\n","| 에폭 3 |  반복 461 / 1327 | 시간 79[s] | 퍼플렉서티 138.75\n","| 에폭 3 |  반복 481 / 1327 | 시간 82[s] | 퍼플렉서티 134.64\n","| 에폭 3 |  반복 501 / 1327 | 시간 85[s] | 퍼플렉서티 147.90\n","| 에폭 3 |  반복 521 / 1327 | 시간 89[s] | 퍼플렉서티 152.35\n","| 에폭 3 |  반복 541 / 1327 | 시간 93[s] | 퍼플렉서티 158.11\n","| 에폭 3 |  반복 561 / 1327 | 시간 96[s] | 퍼플렉서티 133.58\n","| 에폭 3 |  반복 581 / 1327 | 시간 99[s] | 퍼플렉서티 121.41\n","| 에폭 3 |  반복 601 / 1327 | 시간 103[s] | 퍼플렉서티 169.37\n","| 에폭 3 |  반복 621 / 1327 | 시간 106[s] | 퍼플렉서티 159.76\n","| 에폭 3 |  반복 641 / 1327 | 시간 109[s] | 퍼플렉서티 143.98\n","| 에폭 3 |  반복 661 / 1327 | 시간 113[s] | 퍼플렉서티 137.68\n","| 에폭 3 |  반복 681 / 1327 | 시간 116[s] | 퍼플렉서티 117.41\n","| 에폭 3 |  반복 701 / 1327 | 시간 120[s] | 퍼플렉서티 135.59\n","| 에폭 3 |  반복 721 / 1327 | 시간 123[s] | 퍼플렉서티 140.01\n","| 에폭 3 |  반복 741 / 1327 | 시간 126[s] | 퍼플렉서티 119.38\n","| 에폭 3 |  반복 761 / 1327 | 시간 130[s] | 퍼플렉서티 113.59\n","| 에폭 3 |  반복 781 / 1327 | 시간 134[s] | 퍼플렉서티 120.17\n","| 에폭 3 |  반복 801 / 1327 | 시간 137[s] | 퍼플렉서티 135.59\n","| 에폭 3 |  반복 821 / 1327 | 시간 140[s] | 퍼플렉서티 131.21\n","| 에폭 3 |  반복 841 / 1327 | 시간 144[s] | 퍼플렉서티 134.92\n","| 에폭 3 |  반복 861 / 1327 | 시간 147[s] | 퍼플렉서티 130.10\n","| 에폭 3 |  반복 881 / 1327 | 시간 151[s] | 퍼플렉서티 119.74\n","| 에폭 3 |  반복 901 / 1327 | 시간 154[s] | 퍼플렉서티 152.56\n","| 에폭 3 |  반복 921 / 1327 | 시간 158[s] | 퍼플렉서티 133.24\n","| 에폭 3 |  반복 941 / 1327 | 시간 161[s] | 퍼플렉서티 138.25\n","| 에폭 3 |  반복 961 / 1327 | 시간 164[s] | 퍼플렉서티 151.03\n","| 에폭 3 |  반복 981 / 1327 | 시간 168[s] | 퍼플렉서티 143.07\n","| 에폭 3 |  반복 1001 / 1327 | 시간 171[s] | 퍼플렉서티 122.59\n","| 에폭 3 |  반복 1021 / 1327 | 시간 175[s] | 퍼플렉서티 146.72\n","| 에폭 3 |  반복 1041 / 1327 | 시간 178[s] | 퍼플렉서티 128.86\n","| 에폭 3 |  반복 1061 / 1327 | 시간 181[s] | 퍼플렉서티 120.91\n","| 에폭 3 |  반복 1081 / 1327 | 시간 185[s] | 퍼플렉서티 100.88\n","| 에폭 3 |  반복 1101 / 1327 | 시간 189[s] | 퍼플렉서티 107.15\n","| 에폭 3 |  반복 1121 / 1327 | 시간 192[s] | 퍼플렉서티 141.77\n","| 에폭 3 |  반복 1141 / 1327 | 시간 195[s] | 퍼플렉서티 132.75\n","| 에폭 3 |  반복 1161 / 1327 | 시간 199[s] | 퍼플렉서티 115.76\n","| 에폭 3 |  반복 1181 / 1327 | 시간 202[s] | 퍼플렉서티 122.44\n","| 에폭 3 |  반복 1201 / 1327 | 시간 206[s] | 퍼플렉서티 103.37\n","| 에폭 3 |  반복 1221 / 1327 | 시간 209[s] | 퍼플렉서티 103.36\n","| 에폭 3 |  반복 1241 / 1327 | 시간 213[s] | 퍼플렉서티 122.54\n","| 에폭 3 |  반복 1261 / 1327 | 시간 216[s] | 퍼플렉서티 115.59\n","| 에폭 3 |  반복 1281 / 1327 | 시간 219[s] | 퍼플렉서티 115.98\n","| 에폭 3 |  반복 1301 / 1327 | 시간 222[s] | 퍼플렉서티 146.95\n","| 에폭 3 |  반복 1321 / 1327 | 시간 226[s] | 퍼플렉서티 143.72\n","퍼플렉서티 평가 중 ...\n","209 / 210\n","검증 퍼플렉서티:  124.00266\n","--------------------------------------------------\n","| 에폭 4 |  반복 1 / 1327 | 시간 0[s] | 퍼플렉서티 192.42\n","| 에폭 4 |  반복 21 / 1327 | 시간 3[s] | 퍼플렉서티 128.61\n","| 에폭 4 |  반복 41 / 1327 | 시간 6[s] | 퍼플렉서티 124.43\n","| 에폭 4 |  반복 61 / 1327 | 시간 9[s] | 퍼플렉서티 118.97\n","| 에폭 4 |  반복 81 / 1327 | 시간 14[s] | 퍼플렉서티 103.93\n","| 에폭 4 |  반복 101 / 1327 | 시간 17[s] | 퍼플렉서티 100.09\n","| 에폭 4 |  반복 121 / 1327 | 시간 20[s] | 퍼플렉서티 110.39\n","| 에폭 4 |  반복 141 / 1327 | 시간 23[s] | 퍼플렉서티 119.62\n","| 에폭 4 |  반복 161 / 1327 | 시간 27[s] | 퍼플렉서티 135.65\n","| 에폭 4 |  반복 181 / 1327 | 시간 30[s] | 퍼플렉서티 144.34\n","| 에폭 4 |  반복 201 / 1327 | 시간 34[s] | 퍼플렉서티 137.64\n","| 에폭 4 |  반복 221 / 1327 | 시간 37[s] | 퍼플렉서티 133.53\n","| 에폭 4 |  반복 241 / 1327 | 시간 41[s] | 퍼플렉서티 126.94\n","| 에폭 4 |  반복 261 / 1327 | 시간 44[s] | 퍼플렉서티 136.92\n","| 에폭 4 |  반복 281 / 1327 | 시간 47[s] | 퍼플렉서티 133.62\n","| 에폭 4 |  반복 301 / 1327 | 시간 50[s] | 퍼플렉서티 113.44\n","| 에폭 4 |  반복 321 / 1327 | 시간 55[s] | 퍼플렉서티 90.31\n","| 에폭 4 |  반복 341 / 1327 | 시간 58[s] | 퍼플렉서티 129.28\n","| 에폭 4 |  반복 361 / 1327 | 시간 61[s] | 퍼플렉서티 138.24\n","| 에폭 4 |  반복 381 / 1327 | 시간 64[s] | 퍼플렉서티 112.08\n","| 에폭 4 |  반복 401 / 1327 | 시간 69[s] | 퍼플렉서티 126.84\n","| 에폭 4 |  반복 421 / 1327 | 시간 73[s] | 퍼플렉서티 109.83\n","| 에폭 4 |  반복 441 / 1327 | 시간 76[s] | 퍼플렉서티 118.04\n","| 에폭 4 |  반복 461 / 1327 | 시간 81[s] | 퍼플렉서티 118.08\n","| 에폭 4 |  반복 481 / 1327 | 시간 85[s] | 퍼플렉서티 114.62\n","| 에폭 4 |  반복 501 / 1327 | 시간 88[s] | 퍼플렉서티 128.41\n","| 에폭 4 |  반복 521 / 1327 | 시간 91[s] | 퍼플렉서티 133.09\n","| 에폭 4 |  반복 541 / 1327 | 시간 94[s] | 퍼플렉서티 134.35\n","| 에폭 4 |  반복 561 / 1327 | 시간 98[s] | 퍼플렉서티 114.47\n","| 에폭 4 |  반복 581 / 1327 | 시간 101[s] | 퍼플렉서티 104.41\n","| 에폭 4 |  반복 601 / 1327 | 시간 105[s] | 퍼플렉서티 144.80\n","| 에폭 4 |  반복 621 / 1327 | 시간 108[s] | 퍼플렉서티 137.10\n","| 에폭 4 |  반복 641 / 1327 | 시간 112[s] | 퍼플렉서티 124.44\n","| 에폭 4 |  반복 661 / 1327 | 시간 115[s] | 퍼플렉서티 117.18\n","| 에폭 4 |  반복 681 / 1327 | 시간 118[s] | 퍼플렉서티 100.86\n","| 에폭 4 |  반복 701 / 1327 | 시간 122[s] | 퍼플렉서티 117.68\n","| 에폭 4 |  반복 721 / 1327 | 시간 126[s] | 퍼플렉서티 119.45\n","| 에폭 4 |  반복 741 / 1327 | 시간 129[s] | 퍼플렉서티 103.06\n","| 에폭 4 |  반복 761 / 1327 | 시간 132[s] | 퍼플렉서티 96.69\n","| 에폭 4 |  반복 781 / 1327 | 시간 135[s] | 퍼플렉서티 103.86\n","| 에폭 4 |  반복 801 / 1327 | 시간 141[s] | 퍼플렉서티 117.45\n","| 에폭 4 |  반복 821 / 1327 | 시간 144[s] | 퍼플렉서티 116.92\n","| 에폭 4 |  반복 841 / 1327 | 시간 147[s] | 퍼플렉서티 116.14\n","| 에폭 4 |  반복 861 / 1327 | 시간 150[s] | 퍼플렉서티 113.12\n","| 에폭 4 |  반복 881 / 1327 | 시간 154[s] | 퍼플렉서티 103.68\n","| 에폭 4 |  반복 901 / 1327 | 시간 158[s] | 퍼플렉서티 132.75\n","| 에폭 4 |  반복 921 / 1327 | 시간 161[s] | 퍼플렉서티 115.09\n","| 에폭 4 |  반복 941 / 1327 | 시간 164[s] | 퍼플렉서티 122.80\n","| 에폭 4 |  반복 961 / 1327 | 시간 168[s] | 퍼플렉서티 133.27\n","| 에폭 4 |  반복 981 / 1327 | 시간 171[s] | 퍼플렉서티 126.94\n","| 에폭 4 |  반복 1001 / 1327 | 시간 174[s] | 퍼플렉서티 108.54\n","| 에폭 4 |  반복 1021 / 1327 | 시간 177[s] | 퍼플렉서티 128.95\n","| 에폭 4 |  반복 1041 / 1327 | 시간 182[s] | 퍼플렉서티 112.44\n","| 에폭 4 |  반복 1061 / 1327 | 시간 185[s] | 퍼플렉서티 106.41\n","| 에폭 4 |  반복 1081 / 1327 | 시간 188[s] | 퍼플렉서티 87.27\n","| 에폭 4 |  반복 1101 / 1327 | 시간 191[s] | 퍼플렉서티 91.11\n","| 에폭 4 |  반복 1121 / 1327 | 시간 195[s] | 퍼플렉서티 123.18\n","| 에폭 4 |  반복 1141 / 1327 | 시간 198[s] | 퍼플렉서티 116.54\n","| 에폭 4 |  반복 1161 / 1327 | 시간 202[s] | 퍼플렉서티 100.49\n","| 에폭 4 |  반복 1181 / 1327 | 시간 205[s] | 퍼플렉서티 108.27\n","| 에폭 4 |  반복 1201 / 1327 | 시간 209[s] | 퍼플렉서티 91.15\n","| 에폭 4 |  반복 1221 / 1327 | 시간 212[s] | 퍼플렉서티 89.94\n","| 에폭 4 |  반복 1241 / 1327 | 시간 215[s] | 퍼플렉서티 108.38\n","| 에폭 4 |  반복 1261 / 1327 | 시간 218[s] | 퍼플렉서티 103.04\n","| 에폭 4 |  반복 1281 / 1327 | 시간 223[s] | 퍼플렉서티 101.82\n","| 에폭 4 |  반복 1301 / 1327 | 시간 226[s] | 퍼플렉서티 130.48\n","| 에폭 4 |  반복 1321 / 1327 | 시간 229[s] | 퍼플렉서티 126.71\n","퍼플렉서티 평가 중 ...\n","209 / 210\n","검증 퍼플렉서티:  112.62529\n","--------------------------------------------------\n","| 에폭 5 |  반복 1 / 1327 | 시간 0[s] | 퍼플렉서티 180.67\n","| 에폭 5 |  반복 21 / 1327 | 시간 3[s] | 퍼플렉서티 112.33\n","| 에폭 5 |  반복 41 / 1327 | 시간 7[s] | 퍼플렉서티 109.04\n","| 에폭 5 |  반복 61 / 1327 | 시간 10[s] | 퍼플렉서티 105.41\n","| 에폭 5 |  반복 81 / 1327 | 시간 14[s] | 퍼플렉서티 91.73\n","| 에폭 5 |  반복 101 / 1327 | 시간 17[s] | 퍼플렉서티 89.02\n","| 에폭 5 |  반복 121 / 1327 | 시간 21[s] | 퍼플렉서티 97.27\n","| 에폭 5 |  반복 141 / 1327 | 시간 24[s] | 퍼플렉서티 105.64\n","| 에폭 5 |  반복 161 / 1327 | 시간 27[s] | 퍼플렉서티 120.02\n","| 에폭 5 |  반복 181 / 1327 | 시간 31[s] | 퍼플렉서티 127.27\n","| 에폭 5 |  반복 201 / 1327 | 시간 35[s] | 퍼플렉서티 122.88\n","| 에폭 5 |  반복 221 / 1327 | 시간 38[s] | 퍼플렉서티 119.60\n","| 에폭 5 |  반복 241 / 1327 | 시간 41[s] | 퍼플렉서티 113.39\n","| 에폭 5 |  반복 261 / 1327 | 시간 44[s] | 퍼플렉서티 121.08\n","| 에폭 5 |  반복 281 / 1327 | 시간 48[s] | 퍼플렉서티 118.91\n","| 에폭 5 |  반복 301 / 1327 | 시간 51[s] | 퍼플렉서티 99.77\n","| 에폭 5 |  반복 321 / 1327 | 시간 54[s] | 퍼플렉서티 80.62\n","| 에폭 5 |  반복 341 / 1327 | 시간 58[s] | 퍼플렉서티 115.14\n","| 에폭 5 |  반복 361 / 1327 | 시간 62[s] | 퍼플렉서티 123.02\n","| 에폭 5 |  반복 381 / 1327 | 시간 65[s] | 퍼플렉서티 99.79\n","| 에폭 5 |  반복 401 / 1327 | 시간 68[s] | 퍼플렉서티 113.57\n","| 에폭 5 |  반복 421 / 1327 | 시간 71[s] | 퍼플렉서티 97.65\n","| 에폭 5 |  반복 441 / 1327 | 시간 75[s] | 퍼플렉서티 106.09\n","| 에폭 5 |  반복 461 / 1327 | 시간 78[s] | 퍼플렉서티 103.22\n","| 에폭 5 |  반복 481 / 1327 | 시간 82[s] | 퍼플렉서티 102.99\n","| 에폭 5 |  반복 501 / 1327 | 시간 85[s] | 퍼플렉서티 115.51\n","| 에폭 5 |  반복 521 / 1327 | 시간 89[s] | 퍼플렉서티 117.39\n","| 에폭 5 |  반복 541 / 1327 | 시간 92[s] | 퍼플렉서티 121.31\n","| 에폭 5 |  반복 561 / 1327 | 시간 95[s] | 퍼플렉서티 100.48\n","| 에폭 5 |  반복 581 / 1327 | 시간 99[s] | 퍼플렉서티 93.22\n","| 에폭 5 |  반복 601 / 1327 | 시간 102[s] | 퍼플렉서티 132.63\n","| 에폭 5 |  반복 621 / 1327 | 시간 106[s] | 퍼플렉서티 121.63\n","| 에폭 5 |  반복 641 / 1327 | 시간 109[s] | 퍼플렉서티 111.25\n","| 에폭 5 |  반복 661 / 1327 | 시간 112[s] | 퍼플렉서티 103.42\n","| 에폭 5 |  반복 681 / 1327 | 시간 116[s] | 퍼플렉서티 91.03\n","| 에폭 5 |  반복 701 / 1327 | 시간 119[s] | 퍼플렉서티 106.13\n","| 에폭 5 |  반복 721 / 1327 | 시간 122[s] | 퍼플렉서티 108.77\n","| 에폭 5 |  반복 741 / 1327 | 시간 126[s] | 퍼플렉서티 92.13\n","| 에폭 5 |  반복 761 / 1327 | 시간 130[s] | 퍼플렉서티 85.90\n","| 에폭 5 |  반복 781 / 1327 | 시간 133[s] | 퍼플렉서티 94.27\n","| 에폭 5 |  반복 801 / 1327 | 시간 136[s] | 퍼플렉서티 105.65\n","| 에폭 5 |  반복 821 / 1327 | 시간 139[s] | 퍼플렉서티 105.02\n","| 에폭 5 |  반복 841 / 1327 | 시간 143[s] | 퍼플렉서티 105.20\n","| 에폭 5 |  반복 861 / 1327 | 시간 146[s] | 퍼플렉서티 101.79\n","| 에폭 5 |  반복 881 / 1327 | 시간 150[s] | 퍼플렉서티 95.16\n","| 에폭 5 |  반복 901 / 1327 | 시간 153[s] | 퍼플렉서티 119.05\n","| 에폭 5 |  반복 921 / 1327 | 시간 157[s] | 퍼플렉서티 105.07\n","| 에폭 5 |  반복 941 / 1327 | 시간 160[s] | 퍼플렉서티 111.55\n","| 에폭 5 |  반복 961 / 1327 | 시간 163[s] | 퍼플렉서티 121.10\n","| 에폭 5 |  반복 981 / 1327 | 시간 166[s] | 퍼플렉서티 114.97\n","| 에폭 5 |  반복 1001 / 1327 | 시간 171[s] | 퍼플렉서티 98.35\n","| 에폭 5 |  반복 1021 / 1327 | 시간 174[s] | 퍼플렉서티 117.39\n","| 에폭 5 |  반복 1041 / 1327 | 시간 177[s] | 퍼플렉서티 100.55\n","| 에폭 5 |  반복 1061 / 1327 | 시간 180[s] | 퍼플렉서티 95.13\n","| 에폭 5 |  반복 1081 / 1327 | 시간 184[s] | 퍼플렉서티 78.87\n","| 에폭 5 |  반복 1101 / 1327 | 시간 187[s] | 퍼플렉서티 82.12\n","| 에폭 5 |  반복 1121 / 1327 | 시간 190[s] | 퍼플렉서티 110.79\n","| 에폭 5 |  반복 1141 / 1327 | 시간 194[s] | 퍼플렉서티 106.85\n","| 에폭 5 |  반복 1161 / 1327 | 시간 198[s] | 퍼플렉서티 90.34\n","| 에폭 5 |  반복 1181 / 1327 | 시간 201[s] | 퍼플렉서티 99.67\n","| 에폭 5 |  반복 1201 / 1327 | 시간 204[s] | 퍼플렉서티 82.87\n","| 에폭 5 |  반복 1221 / 1327 | 시간 207[s] | 퍼플렉서티 81.91\n","| 에폭 5 |  반복 1241 / 1327 | 시간 211[s] | 퍼플렉서티 98.23\n","| 에폭 5 |  반복 1261 / 1327 | 시간 214[s] | 퍼플렉서티 93.69\n","| 에폭 5 |  반복 1281 / 1327 | 시간 217[s] | 퍼플렉서티 92.74\n","| 에폭 5 |  반복 1301 / 1327 | 시간 222[s] | 퍼플렉서티 118.23\n","| 에폭 5 |  반복 1321 / 1327 | 시간 226[s] | 퍼플렉서티 115.87\n","퍼플렉서티 평가 중 ...\n","209 / 210\n","검증 퍼플렉서티:  105.257454\n","--------------------------------------------------\n","| 에폭 6 |  반복 1 / 1327 | 시간 0[s] | 퍼플렉서티 160.16\n","| 에폭 6 |  반복 21 / 1327 | 시간 3[s] | 퍼플렉서티 101.42\n","| 에폭 6 |  반복 41 / 1327 | 시간 6[s] | 퍼플렉서티 99.49\n","| 에폭 6 |  반복 61 / 1327 | 시간 11[s] | 퍼플렉서티 95.55\n","| 에폭 6 |  반복 81 / 1327 | 시간 14[s] | 퍼플렉서티 83.72\n","| 에폭 6 |  반복 101 / 1327 | 시간 17[s] | 퍼플렉서티 80.70\n","| 에폭 6 |  반복 121 / 1327 | 시간 20[s] | 퍼플렉서티 89.46\n","| 에폭 6 |  반복 141 / 1327 | 시간 24[s] | 퍼플렉서티 97.27\n","| 에폭 6 |  반복 161 / 1327 | 시간 27[s] | 퍼플렉서티 109.95\n","| 에폭 6 |  반복 181 / 1327 | 시간 30[s] | 퍼플렉서티 118.66\n","| 에폭 6 |  반복 201 / 1327 | 시간 35[s] | 퍼플렉서티 113.54\n","| 에폭 6 |  반복 221 / 1327 | 시간 41[s] | 퍼플렉서티 110.90\n","| 에폭 6 |  반복 241 / 1327 | 시간 45[s] | 퍼플렉서티 104.64\n","| 에폭 6 |  반복 261 / 1327 | 시간 48[s] | 퍼플렉서티 111.57\n","| 에폭 6 |  반복 281 / 1327 | 시간 52[s] | 퍼플렉서티 109.82\n","| 에폭 6 |  반복 301 / 1327 | 시간 57[s] | 퍼플렉서티 90.60\n","| 에폭 6 |  반복 321 / 1327 | 시간 60[s] | 퍼플렉서티 74.46\n","| 에폭 6 |  반복 341 / 1327 | 시간 63[s] | 퍼플렉서티 105.69\n","| 에폭 6 |  반복 361 / 1327 | 시간 68[s] | 퍼플렉서티 111.33\n","| 에폭 6 |  반복 381 / 1327 | 시간 71[s] | 퍼플렉서티 92.17\n","| 에폭 6 |  반복 401 / 1327 | 시간 75[s] | 퍼플렉서티 105.21\n","| 에폭 6 |  반복 421 / 1327 | 시간 78[s] | 퍼플렉서티 88.55\n","| 에폭 6 |  반복 441 / 1327 | 시간 82[s] | 퍼플렉서티 97.23\n","| 에폭 6 |  반복 461 / 1327 | 시간 85[s] | 퍼플렉서티 95.36\n","| 에폭 6 |  반복 481 / 1327 | 시간 88[s] | 퍼플렉서티 95.21\n","| 에폭 6 |  반복 501 / 1327 | 시간 91[s] | 퍼플렉서티 104.96\n","| 에폭 6 |  반복 521 / 1327 | 시간 95[s] | 퍼플렉서티 108.48\n","| 에폭 6 |  반복 541 / 1327 | 시간 99[s] | 퍼플렉서티 109.11\n","| 에폭 6 |  반복 561 / 1327 | 시간 102[s] | 퍼플렉서티 93.01\n","| 에폭 6 |  반복 581 / 1327 | 시간 105[s] | 퍼플렉서티 84.72\n","| 에폭 6 |  반복 601 / 1327 | 시간 109[s] | 퍼플렉서티 119.85\n","| 에폭 6 |  반복 621 / 1327 | 시간 113[s] | 퍼플렉서티 113.03\n","| 에폭 6 |  반복 641 / 1327 | 시간 117[s] | 퍼플렉서티 102.74\n","| 에폭 6 |  반복 661 / 1327 | 시간 121[s] | 퍼플렉서티 96.10\n","| 에폭 6 |  반복 681 / 1327 | 시간 126[s] | 퍼플렉서티 83.30\n","| 에폭 6 |  반복 701 / 1327 | 시간 129[s] | 퍼플렉서티 97.59\n","| 에폭 6 |  반복 721 / 1327 | 시간 132[s] | 퍼플렉서티 98.60\n","| 에폭 6 |  반복 741 / 1327 | 시간 137[s] | 퍼플렉서티 86.36\n","| 에폭 6 |  반복 761 / 1327 | 시간 141[s] | 퍼플렉서티 79.03\n","| 에폭 6 |  반복 781 / 1327 | 시간 144[s] | 퍼플렉서티 86.51\n","| 에폭 6 |  반복 801 / 1327 | 시간 148[s] | 퍼플렉서티 98.67\n","| 에폭 6 |  반복 821 / 1327 | 시간 152[s] | 퍼플렉서티 96.49\n","| 에폭 6 |  반복 841 / 1327 | 시간 157[s] | 퍼플렉서티 97.66\n","| 에폭 6 |  반복 861 / 1327 | 시간 160[s] | 퍼플렉서티 95.25\n","| 에폭 6 |  반복 881 / 1327 | 시간 163[s] | 퍼플렉서티 87.61\n","| 에폭 6 |  반복 901 / 1327 | 시간 169[s] | 퍼플렉서티 111.65\n","| 에폭 6 |  반복 921 / 1327 | 시간 172[s] | 퍼플렉서티 98.17\n","| 에폭 6 |  반복 941 / 1327 | 시간 175[s] | 퍼플렉서티 104.23\n","| 에폭 6 |  반복 961 / 1327 | 시간 179[s] | 퍼플렉서티 111.45\n","| 에폭 6 |  반복 981 / 1327 | 시간 183[s] | 퍼플렉서티 106.25\n","| 에폭 6 |  반복 1001 / 1327 | 시간 187[s] | 퍼플렉서티 92.58\n","| 에폭 6 |  반복 1021 / 1327 | 시간 191[s] | 퍼플렉서티 107.41\n","| 에폭 6 |  반복 1041 / 1327 | 시간 194[s] | 퍼플렉서티 94.66\n","| 에폭 6 |  반복 1061 / 1327 | 시간 199[s] | 퍼플렉서티 89.11\n","| 에폭 6 |  반복 1081 / 1327 | 시간 202[s] | 퍼플렉서티 72.77\n","| 에폭 6 |  반복 1101 / 1327 | 시간 206[s] | 퍼플렉서티 75.31\n","| 에폭 6 |  반복 1121 / 1327 | 시간 211[s] | 퍼플렉서티 104.28\n","| 에폭 6 |  반복 1141 / 1327 | 시간 214[s] | 퍼플렉서티 98.79\n","| 에폭 6 |  반복 1161 / 1327 | 시간 217[s] | 퍼플렉서티 82.72\n","| 에폭 6 |  반복 1181 / 1327 | 시간 222[s] | 퍼플렉서티 91.72\n","| 에폭 6 |  반복 1201 / 1327 | 시간 226[s] | 퍼플렉서티 76.87\n","| 에폭 6 |  반복 1221 / 1327 | 시간 230[s] | 퍼플렉서티 75.66\n","| 에폭 6 |  반복 1241 / 1327 | 시간 233[s] | 퍼플렉서티 91.20\n","| 에폭 6 |  반복 1261 / 1327 | 시간 237[s] | 퍼플렉서티 86.68\n","| 에폭 6 |  반복 1281 / 1327 | 시간 242[s] | 퍼플렉서티 87.22\n","| 에폭 6 |  반복 1301 / 1327 | 시간 245[s] | 퍼플렉서티 110.44\n","| 에폭 6 |  반복 1321 / 1327 | 시간 248[s] | 퍼플렉서티 107.15\n","퍼플렉서티 평가 중 ...\n","209 / 210\n","검증 퍼플렉서티:  100.50021\n","--------------------------------------------------\n","| 에폭 7 |  반복 1 / 1327 | 시간 0[s] | 퍼플렉서티 154.35\n","| 에폭 7 |  반복 21 / 1327 | 시간 3[s] | 퍼플렉서티 94.52\n","| 에폭 7 |  반복 41 / 1327 | 시간 8[s] | 퍼플렉서티 91.35\n","| 에폭 7 |  반복 61 / 1327 | 시간 11[s] | 퍼플렉서티 87.98\n","| 에폭 7 |  반복 81 / 1327 | 시간 15[s] | 퍼플렉서티 79.15\n","| 에폭 7 |  반복 101 / 1327 | 시간 19[s] | 퍼플렉서티 75.30\n","| 에폭 7 |  반복 121 / 1327 | 시간 23[s] | 퍼플렉서티 82.00\n","| 에폭 7 |  반복 141 / 1327 | 시간 27[s] | 퍼플렉서티 89.35\n","| 에폭 7 |  반복 161 / 1327 | 시간 31[s] | 퍼플렉서티 103.86\n","| 에폭 7 |  반복 181 / 1327 | 시간 34[s] | 퍼플렉서티 109.37\n","| 에폭 7 |  반복 201 / 1327 | 시간 39[s] | 퍼플렉서티 107.30\n","| 에폭 7 |  반복 221 / 1327 | 시간 42[s] | 퍼플렉서티 102.11\n","| 에폭 7 |  반복 241 / 1327 | 시간 46[s] | 퍼플렉서티 97.33\n","| 에폭 7 |  반복 261 / 1327 | 시간 50[s] | 퍼플렉서티 104.76\n","| 에폭 7 |  반복 281 / 1327 | 시간 53[s] | 퍼플렉서티 102.93\n","| 에폭 7 |  반복 301 / 1327 | 시간 57[s] | 퍼플렉서티 85.37\n","| 에폭 7 |  반복 321 / 1327 | 시간 61[s] | 퍼플렉서티 68.07\n","| 에폭 7 |  반복 341 / 1327 | 시간 64[s] | 퍼플렉서티 98.30\n","| 에폭 7 |  반복 361 / 1327 | 시간 67[s] | 퍼플렉서티 103.09\n","| 에폭 7 |  반복 381 / 1327 | 시간 71[s] | 퍼플렉서티 85.98\n","| 에폭 7 |  반복 401 / 1327 | 시간 74[s] | 퍼플렉서티 96.99\n","| 에폭 7 |  반복 421 / 1327 | 시간 78[s] | 퍼플렉서티 83.89\n","| 에폭 7 |  반복 441 / 1327 | 시간 81[s] | 퍼플렉서티 90.84\n","| 에폭 7 |  반복 461 / 1327 | 시간 85[s] | 퍼플렉서티 88.73\n","| 에폭 7 |  반복 481 / 1327 | 시간 89[s] | 퍼플렉서티 88.45\n","| 에폭 7 |  반복 501 / 1327 | 시간 92[s] | 퍼플렉서티 98.32\n","| 에폭 7 |  반복 521 / 1327 | 시간 96[s] | 퍼플렉서티 102.08\n","| 에폭 7 |  반복 541 / 1327 | 시간 101[s] | 퍼플렉서티 101.96\n","| 에폭 7 |  반복 561 / 1327 | 시간 104[s] | 퍼플렉서티 86.59\n","| 에폭 7 |  반복 581 / 1327 | 시간 109[s] | 퍼플렉서티 79.77\n","| 에폭 7 |  반복 601 / 1327 | 시간 112[s] | 퍼플렉서티 112.35\n","| 에폭 7 |  반복 621 / 1327 | 시간 117[s] | 퍼플렉서티 104.96\n","| 에폭 7 |  반복 641 / 1327 | 시간 121[s] | 퍼플렉서티 96.53\n","| 에폭 7 |  반복 661 / 1327 | 시간 124[s] | 퍼플렉서티 89.16\n","| 에폭 7 |  반복 681 / 1327 | 시간 129[s] | 퍼플렉서티 77.86\n","| 에폭 7 |  반복 701 / 1327 | 시간 133[s] | 퍼플렉서티 92.13\n","| 에폭 7 |  반복 721 / 1327 | 시간 136[s] | 퍼플렉서티 92.93\n","| 에폭 7 |  반복 741 / 1327 | 시간 141[s] | 퍼플렉서티 79.80\n","| 에폭 7 |  반복 761 / 1327 | 시간 145[s] | 퍼플렉서티 73.59\n","| 에폭 7 |  반복 781 / 1327 | 시간 149[s] | 퍼플렉서티 82.03\n","| 에폭 7 |  반복 801 / 1327 | 시간 152[s] | 퍼플렉서티 91.67\n","| 에폭 7 |  반복 821 / 1327 | 시간 156[s] | 퍼플렉서티 91.22\n","| 에폭 7 |  반복 841 / 1327 | 시간 161[s] | 퍼플렉서티 91.34\n","| 에폭 7 |  반복 861 / 1327 | 시간 164[s] | 퍼플렉서티 88.82\n","| 에폭 7 |  반복 881 / 1327 | 시간 167[s] | 퍼플렉서티 82.23\n","| 에폭 7 |  반복 901 / 1327 | 시간 171[s] | 퍼플렉서티 104.46\n","| 에폭 7 |  반복 921 / 1327 | 시간 175[s] | 퍼플렉서티 92.42\n","| 에폭 7 |  반복 941 / 1327 | 시간 178[s] | 퍼플렉서티 98.07\n","| 에폭 7 |  반복 961 / 1327 | 시간 181[s] | 퍼플렉서티 105.90\n","| 에폭 7 |  반복 981 / 1327 | 시간 185[s] | 퍼플렉서티 100.33\n","| 에폭 7 |  반복 1001 / 1327 | 시간 189[s] | 퍼플렉서티 86.95\n","| 에폭 7 |  반복 1021 / 1327 | 시간 192[s] | 퍼플렉서티 102.43\n","| 에폭 7 |  반복 1041 / 1327 | 시간 195[s] | 퍼플렉서티 89.27\n","| 에폭 7 |  반복 1061 / 1327 | 시간 198[s] | 퍼플렉서티 83.85\n","| 에폭 7 |  반복 1081 / 1327 | 시간 202[s] | 퍼플렉서티 68.52\n","| 에폭 7 |  반복 1101 / 1327 | 시간 206[s] | 퍼플렉서티 70.22\n","| 에폭 7 |  반복 1121 / 1327 | 시간 210[s] | 퍼플렉서티 97.22\n","| 에폭 7 |  반복 1141 / 1327 | 시간 213[s] | 퍼플렉서티 92.39\n","| 에폭 7 |  반복 1161 / 1327 | 시간 218[s] | 퍼플렉서티 78.54\n","| 에폭 7 |  반복 1181 / 1327 | 시간 221[s] | 퍼플렉서티 86.51\n","| 에폭 7 |  반복 1201 / 1327 | 시간 225[s] | 퍼플렉서티 71.75\n","| 에폭 7 |  반복 1221 / 1327 | 시간 230[s] | 퍼플렉서티 71.51\n","| 에폭 7 |  반복 1241 / 1327 | 시간 233[s] | 퍼플렉서티 85.67\n","| 에폭 7 |  반복 1261 / 1327 | 시간 237[s] | 퍼플렉서티 82.94\n","| 에폭 7 |  반복 1281 / 1327 | 시간 241[s] | 퍼플렉서티 81.78\n","| 에폭 7 |  반복 1301 / 1327 | 시간 245[s] | 퍼플렉서티 103.95\n","| 에폭 7 |  반복 1321 / 1327 | 시간 248[s] | 퍼플렉서티 101.34\n","퍼플렉서티 평가 중 ...\n","209 / 210\n","검증 퍼플렉서티:  96.58962\n","--------------------------------------------------\n","| 에폭 8 |  반복 1 / 1327 | 시간 0[s] | 퍼플렉서티 146.73\n","| 에폭 8 |  반복 21 / 1327 | 시간 3[s] | 퍼플렉서티 88.72\n","| 에폭 8 |  반복 41 / 1327 | 시간 7[s] | 퍼플렉서티 87.15\n","| 에폭 8 |  반복 61 / 1327 | 시간 10[s] | 퍼플렉서티 84.63\n","| 에폭 8 |  반복 81 / 1327 | 시간 14[s] | 퍼플렉서티 73.64\n","| 에폭 8 |  반복 101 / 1327 | 시간 17[s] | 퍼플렉서티 70.95\n","| 에폭 8 |  반복 121 / 1327 | 시간 20[s] | 퍼플렉서티 78.02\n","| 에폭 8 |  반복 141 / 1327 | 시간 24[s] | 퍼플렉서티 84.21\n","| 에폭 8 |  반복 161 / 1327 | 시간 27[s] | 퍼플렉서티 97.87\n","| 에폭 8 |  반복 181 / 1327 | 시간 30[s] | 퍼플렉서티 103.64\n","| 에폭 8 |  반복 201 / 1327 | 시간 34[s] | 퍼플렉서티 101.06\n","| 에폭 8 |  반복 221 / 1327 | 시간 38[s] | 퍼플렉서티 97.12\n","| 에폭 8 |  반복 241 / 1327 | 시간 41[s] | 퍼플렉서티 92.60\n","| 에폭 8 |  반복 261 / 1327 | 시간 44[s] | 퍼플렉서티 98.44\n","| 에폭 8 |  반복 281 / 1327 | 시간 48[s] | 퍼플렉서티 96.94\n","| 에폭 8 |  반복 301 / 1327 | 시간 51[s] | 퍼플렉서티 80.15\n","| 에폭 8 |  반복 321 / 1327 | 시간 54[s] | 퍼플렉서티 65.41\n","| 에폭 8 |  반복 341 / 1327 | 시간 57[s] | 퍼플렉서티 93.21\n","| 에폭 8 |  반복 361 / 1327 | 시간 61[s] | 퍼플렉서티 97.98\n","| 에폭 8 |  반복 381 / 1327 | 시간 65[s] | 퍼플렉서티 81.81\n","| 에폭 8 |  반복 401 / 1327 | 시간 68[s] | 퍼플렉서티 91.33\n","| 에폭 8 |  반복 421 / 1327 | 시간 71[s] | 퍼플렉서티 79.20\n","| 에폭 8 |  반복 441 / 1327 | 시간 75[s] | 퍼플렉서티 85.35\n","| 에폭 8 |  반복 461 / 1327 | 시간 78[s] | 퍼플렉서티 84.13\n","| 에폭 8 |  반복 481 / 1327 | 시간 82[s] | 퍼플렉서티 83.55\n","| 에폭 8 |  반복 501 / 1327 | 시간 86[s] | 퍼플렉서티 92.51\n","| 에폭 8 |  반복 521 / 1327 | 시간 90[s] | 퍼플렉서티 96.02\n","| 에폭 8 |  반복 541 / 1327 | 시간 94[s] | 퍼플렉서티 97.19\n","| 에폭 8 |  반복 561 / 1327 | 시간 97[s] | 퍼플렉서티 81.50\n","| 에폭 8 |  반복 581 / 1327 | 시간 100[s] | 퍼플렉서티 75.05\n","| 에폭 8 |  반복 601 / 1327 | 시간 106[s] | 퍼플렉서티 107.28\n","| 에폭 8 |  반복 621 / 1327 | 시간 109[s] | 퍼플렉서티 100.53\n","| 에폭 8 |  반복 641 / 1327 | 시간 112[s] | 퍼플렉서티 90.44\n","| 에폭 8 |  반복 661 / 1327 | 시간 117[s] | 퍼플렉서티 83.92\n","| 에폭 8 |  반복 681 / 1327 | 시간 121[s] | 퍼플렉서티 73.71\n","| 에폭 8 |  반복 701 / 1327 | 시간 125[s] | 퍼플렉서티 87.28\n","| 에폭 8 |  반복 721 / 1327 | 시간 128[s] | 퍼플렉서티 87.60\n","| 에폭 8 |  반복 741 / 1327 | 시간 132[s] | 퍼플렉서티 75.69\n","| 에폭 8 |  반복 761 / 1327 | 시간 136[s] | 퍼플렉서티 68.79\n","| 에폭 8 |  반복 781 / 1327 | 시간 140[s] | 퍼플렉서티 77.05\n","| 에폭 8 |  반복 801 / 1327 | 시간 143[s] | 퍼플렉서티 87.36\n","| 에폭 8 |  반복 821 / 1327 | 시간 148[s] | 퍼플렉서티 86.17\n","| 에폭 8 |  반복 841 / 1327 | 시간 151[s] | 퍼플렉서티 86.58\n","| 에폭 8 |  반복 861 / 1327 | 시간 156[s] | 퍼플렉서티 85.71\n","| 에폭 8 |  반복 881 / 1327 | 시간 159[s] | 퍼플렉서티 78.23\n","| 에폭 8 |  반복 901 / 1327 | 시간 163[s] | 퍼플렉서티 99.60\n","| 에폭 8 |  반복 921 / 1327 | 시간 167[s] | 퍼플렉서티 87.33\n","| 에폭 8 |  반복 941 / 1327 | 시간 170[s] | 퍼플렉서티 92.96\n","| 에폭 8 |  반복 961 / 1327 | 시간 174[s] | 퍼플렉서티 99.88\n","| 에폭 8 |  반복 981 / 1327 | 시간 179[s] | 퍼플렉서티 95.54\n","| 에폭 8 |  반복 1001 / 1327 | 시간 182[s] | 퍼플렉서티 82.85\n","| 에폭 8 |  반복 1021 / 1327 | 시간 186[s] | 퍼플렉서티 96.26\n","| 에폭 8 |  반복 1041 / 1327 | 시간 190[s] | 퍼플렉서티 83.96\n","| 에폭 8 |  반복 1061 / 1327 | 시간 194[s] | 퍼플렉서티 80.04\n","| 에폭 8 |  반복 1081 / 1327 | 시간 198[s] | 퍼플렉서티 64.88\n","| 에폭 8 |  반복 1101 / 1327 | 시간 201[s] | 퍼플렉서티 67.23\n","| 에폭 8 |  반복 1121 / 1327 | 시간 206[s] | 퍼플렉서티 91.18\n","| 에폭 8 |  반복 1141 / 1327 | 시간 210[s] | 퍼플렉서티 87.88\n","| 에폭 8 |  반복 1161 / 1327 | 시간 213[s] | 퍼플렉서티 74.25\n","| 에폭 8 |  반복 1181 / 1327 | 시간 217[s] | 퍼플렉서티 82.45\n","| 에폭 8 |  반복 1201 / 1327 | 시간 222[s] | 퍼플렉서티 67.71\n","| 에폭 8 |  반복 1221 / 1327 | 시간 225[s] | 퍼플렉서티 67.15\n","| 에폭 8 |  반복 1241 / 1327 | 시간 229[s] | 퍼플렉서티 82.12\n","| 에폭 8 |  반복 1261 / 1327 | 시간 232[s] | 퍼플렉서티 78.22\n","| 에폭 8 |  반복 1281 / 1327 | 시간 237[s] | 퍼플렉서티 77.83\n","| 에폭 8 |  반복 1301 / 1327 | 시간 241[s] | 퍼플렉서티 98.53\n","| 에폭 8 |  반복 1321 / 1327 | 시간 244[s] | 퍼플렉서티 95.57\n","퍼플렉서티 평가 중 ...\n","209 / 210\n","검증 퍼플렉서티:  95.195984\n","--------------------------------------------------\n","| 에폭 9 |  반복 1 / 1327 | 시간 0[s] | 퍼플렉서티 138.56\n","| 에폭 9 |  반복 21 / 1327 | 시간 4[s] | 퍼플렉서티 83.77\n","| 에폭 9 |  반복 41 / 1327 | 시간 7[s] | 퍼플렉서티 82.81\n","| 에폭 9 |  반복 61 / 1327 | 시간 10[s] | 퍼플렉서티 80.30\n","| 에폭 9 |  반복 81 / 1327 | 시간 14[s] | 퍼플렉서티 70.62\n","| 에폭 9 |  반복 101 / 1327 | 시간 18[s] | 퍼플렉서티 67.64\n","| 에폭 9 |  반복 121 / 1327 | 시간 22[s] | 퍼플렉서티 74.34\n","| 에폭 9 |  반복 141 / 1327 | 시간 25[s] | 퍼플렉서티 78.85\n","| 에폭 9 |  반복 161 / 1327 | 시간 28[s] | 퍼플렉서티 93.61\n","| 에폭 9 |  반복 181 / 1327 | 시간 34[s] | 퍼플렉서티 100.26\n","| 에폭 9 |  반복 201 / 1327 | 시간 37[s] | 퍼플렉서티 95.82\n","| 에폭 9 |  반복 221 / 1327 | 시간 40[s] | 퍼플렉서티 93.26\n","| 에폭 9 |  반복 241 / 1327 | 시간 45[s] | 퍼플렉서티 87.96\n","| 에폭 9 |  반복 261 / 1327 | 시간 48[s] | 퍼플렉서티 93.87\n","| 에폭 9 |  반복 281 / 1327 | 시간 53[s] | 퍼플렉서티 92.29\n","| 에폭 9 |  반복 301 / 1327 | 시간 56[s] | 퍼플렉서티 76.24\n","| 에폭 9 |  반복 321 / 1327 | 시간 60[s] | 퍼플렉서티 62.37\n","| 에폭 9 |  반복 341 / 1327 | 시간 64[s] | 퍼플렉서티 88.63\n","| 에폭 9 |  반복 361 / 1327 | 시간 67[s] | 퍼플렉서티 93.09\n","| 에폭 9 |  반복 381 / 1327 | 시간 71[s] | 퍼플렉서티 77.55\n","| 에폭 9 |  반복 401 / 1327 | 시간 76[s] | 퍼플렉서티 87.49\n","| 에폭 9 |  반복 421 / 1327 | 시간 80[s] | 퍼플렉서티 75.51\n","| 에폭 9 |  반복 441 / 1327 | 시간 84[s] | 퍼플렉서티 81.49\n","| 에폭 9 |  반복 461 / 1327 | 시간 87[s] | 퍼플렉서티 79.78\n","| 에폭 9 |  반복 481 / 1327 | 시간 91[s] | 퍼플렉서티 80.41\n","| 에폭 9 |  반복 501 / 1327 | 시간 95[s] | 퍼플렉서티 88.44\n","| 에폭 9 |  반복 521 / 1327 | 시간 98[s] | 퍼플렉서티 91.84\n","| 에폭 9 |  반복 541 / 1327 | 시간 103[s] | 퍼플렉서티 92.11\n","| 에폭 9 |  반복 561 / 1327 | 시간 107[s] | 퍼플렉서티 78.27\n","| 에폭 9 |  반복 581 / 1327 | 시간 110[s] | 퍼플렉서티 72.49\n","| 에폭 9 |  반복 601 / 1327 | 시간 114[s] | 퍼플렉서티 101.34\n","| 에폭 9 |  반복 621 / 1327 | 시간 119[s] | 퍼플렉서티 96.01\n","| 에폭 9 |  반복 641 / 1327 | 시간 122[s] | 퍼플렉서티 85.45\n","| 에폭 9 |  반복 661 / 1327 | 시간 126[s] | 퍼플렉서티 78.96\n","| 에폭 9 |  반복 681 / 1327 | 시간 129[s] | 퍼플렉서티 69.58\n","| 에폭 9 |  반복 701 / 1327 | 시간 135[s] | 퍼플렉서티 82.91\n","| 에폭 9 |  반복 721 / 1327 | 시간 138[s] | 퍼플렉서티 83.45\n","| 에폭 9 |  반복 741 / 1327 | 시간 141[s] | 퍼플렉서티 73.03\n","| 에폭 9 |  반복 761 / 1327 | 시간 145[s] | 퍼플렉서티 65.63\n","| 에폭 9 |  반복 781 / 1327 | 시간 149[s] | 퍼플렉서티 73.69\n","| 에폭 9 |  반복 801 / 1327 | 시간 153[s] | 퍼플렉서티 82.52\n","| 에폭 9 |  반복 821 / 1327 | 시간 157[s] | 퍼플렉서티 82.20\n","| 에폭 9 |  반복 841 / 1327 | 시간 160[s] | 퍼플렉서티 82.42\n","| 에폭 9 |  반복 861 / 1327 | 시간 165[s] | 퍼플렉서티 81.72\n","| 에폭 9 |  반복 881 / 1327 | 시간 168[s] | 퍼플렉서티 74.49\n","| 에폭 9 |  반복 901 / 1327 | 시간 171[s] | 퍼플렉서티 94.18\n","| 에폭 9 |  반복 921 / 1327 | 시간 176[s] | 퍼플렉서티 83.09\n","| 에폭 9 |  반복 941 / 1327 | 시간 180[s] | 퍼플렉서티 89.53\n","| 에폭 9 |  반복 961 / 1327 | 시간 183[s] | 퍼플렉서티 95.52\n","| 에폭 9 |  반복 981 / 1327 | 시간 187[s] | 퍼플렉서티 90.67\n","| 에폭 9 |  반복 1001 / 1327 | 시간 191[s] | 퍼플렉서티 79.02\n","| 에폭 9 |  반복 1021 / 1327 | 시간 196[s] | 퍼플렉서티 92.32\n","| 에폭 9 |  반복 1041 / 1327 | 시간 199[s] | 퍼플렉서티 80.23\n","| 에폭 9 |  반복 1061 / 1327 | 시간 202[s] | 퍼플렉서티 76.06\n","| 에폭 9 |  반복 1081 / 1327 | 시간 208[s] | 퍼플렉서티 62.70\n","| 에폭 9 |  반복 1101 / 1327 | 시간 211[s] | 퍼플렉서티 63.98\n","| 에폭 9 |  반복 1121 / 1327 | 시간 214[s] | 퍼플렉서티 87.45\n","| 에폭 9 |  반복 1141 / 1327 | 시간 218[s] | 퍼플렉서티 83.31\n","| 에폭 9 |  반복 1161 / 1327 | 시간 222[s] | 퍼플렉서티 70.70\n","| 에폭 9 |  반복 1181 / 1327 | 시간 225[s] | 퍼플렉서티 78.52\n","| 에폭 9 |  반복 1201 / 1327 | 시간 228[s] | 퍼플렉서티 65.48\n","| 에폭 9 |  반복 1221 / 1327 | 시간 232[s] | 퍼플렉서티 65.54\n","| 에폭 9 |  반복 1241 / 1327 | 시간 236[s] | 퍼플렉서티 78.15\n","| 에폭 9 |  반복 1261 / 1327 | 시간 239[s] | 퍼플렉서티 75.99\n","| 에폭 9 |  반복 1281 / 1327 | 시간 242[s] | 퍼플렉서티 74.92\n","| 에폭 9 |  반복 1301 / 1327 | 시간 245[s] | 퍼플렉서티 95.07\n","| 에폭 9 |  반복 1321 / 1327 | 시간 249[s] | 퍼플렉서티 91.67\n","퍼플렉서티 평가 중 ...\n","209 / 210\n","검증 퍼플렉서티:  93.009796\n","--------------------------------------------------\n","| 에폭 10 |  반복 1 / 1327 | 시간 0[s] | 퍼플렉서티 137.00\n","| 에폭 10 |  반복 21 / 1327 | 시간 4[s] | 퍼플렉서티 80.81\n","| 에폭 10 |  반복 41 / 1327 | 시간 7[s] | 퍼플렉서티 80.07\n","| 에폭 10 |  반복 61 / 1327 | 시간 12[s] | 퍼플렉서티 77.19\n","| 에폭 10 |  반복 81 / 1327 | 시간 16[s] | 퍼플렉서티 66.85\n","| 에폭 10 |  반복 101 / 1327 | 시간 19[s] | 퍼플렉서티 65.38\n","| 에폭 10 |  반복 121 / 1327 | 시간 24[s] | 퍼플렉서티 71.16\n","| 에폭 10 |  반복 141 / 1327 | 시간 28[s] | 퍼플렉서티 76.43\n","| 에폭 10 |  반복 161 / 1327 | 시간 31[s] | 퍼플렉서티 88.87\n","| 에폭 10 |  반복 181 / 1327 | 시간 35[s] | 퍼플렉서티 94.39\n","| 에폭 10 |  반복 201 / 1327 | 시간 39[s] | 퍼플렉서티 92.48\n","| 에폭 10 |  반복 221 / 1327 | 시간 43[s] | 퍼플렉서티 89.09\n","| 에폭 10 |  반복 241 / 1327 | 시간 46[s] | 퍼플렉서티 83.23\n","| 에폭 10 |  반복 261 / 1327 | 시간 49[s] | 퍼플렉서티 89.27\n","| 에폭 10 |  반복 281 / 1327 | 시간 55[s] | 퍼플렉서티 86.87\n","| 에폭 10 |  반복 301 / 1327 | 시간 58[s] | 퍼플렉서티 73.01\n","| 에폭 10 |  반복 321 / 1327 | 시간 61[s] | 퍼플렉서티 59.77\n","| 에폭 10 |  반복 341 / 1327 | 시간 66[s] | 퍼플렉서티 85.38\n","| 에폭 10 |  반복 361 / 1327 | 시간 70[s] | 퍼플렉서티 88.42\n","| 에폭 10 |  반복 381 / 1327 | 시간 74[s] | 퍼플렉서티 74.35\n","| 에폭 10 |  반복 401 / 1327 | 시간 77[s] | 퍼플렉서티 83.59\n","| 에폭 10 |  반복 421 / 1327 | 시간 81[s] | 퍼플렉서티 71.68\n","| 에폭 10 |  반복 441 / 1327 | 시간 86[s] | 퍼플렉서티 77.89\n","| 에폭 10 |  반복 461 / 1327 | 시간 89[s] | 퍼플렉서티 76.99\n","| 에폭 10 |  반복 481 / 1327 | 시간 92[s] | 퍼플렉서티 76.89\n","| 에폭 10 |  반복 501 / 1327 | 시간 98[s] | 퍼플렉서티 84.80\n","| 에폭 10 |  반복 521 / 1327 | 시간 101[s] | 퍼플렉서티 88.30\n","| 에폭 10 |  반복 541 / 1327 | 시간 105[s] | 퍼플렉서티 87.90\n","| 에폭 10 |  반복 561 / 1327 | 시간 108[s] | 퍼플렉서티 75.64\n","| 에폭 10 |  반복 581 / 1327 | 시간 113[s] | 퍼플렉서티 69.79\n","| 에폭 10 |  반복 601 / 1327 | 시간 117[s] | 퍼플렉서티 97.37\n","| 에폭 10 |  반복 621 / 1327 | 시간 120[s] | 퍼플렉서티 91.15\n","| 에폭 10 |  반복 641 / 1327 | 시간 124[s] | 퍼플렉서티 81.70\n","| 에폭 10 |  반복 661 / 1327 | 시간 129[s] | 퍼플렉서티 76.79\n","| 에폭 10 |  반복 681 / 1327 | 시간 132[s] | 퍼플렉서티 66.93\n","| 에폭 10 |  반복 701 / 1327 | 시간 136[s] | 퍼플렉서티 79.76\n","| 에폭 10 |  반복 721 / 1327 | 시간 140[s] | 퍼플렉서티 80.21\n","| 에폭 10 |  반복 741 / 1327 | 시간 144[s] | 퍼플렉서티 70.86\n","| 에폭 10 |  반복 761 / 1327 | 시간 148[s] | 퍼플렉서티 63.82\n","| 에폭 10 |  반복 781 / 1327 | 시간 151[s] | 퍼플렉서티 70.07\n","| 에폭 10 |  반복 801 / 1327 | 시간 156[s] | 퍼플렉서티 80.27\n","| 에폭 10 |  반복 821 / 1327 | 시간 159[s] | 퍼플렉서티 79.27\n","| 에폭 10 |  반복 841 / 1327 | 시간 163[s] | 퍼플렉서티 79.79\n","| 에폭 10 |  반복 861 / 1327 | 시간 166[s] | 퍼플렉서티 78.58\n","| 에폭 10 |  반복 881 / 1327 | 시간 171[s] | 퍼플렉서티 72.90\n","| 에폭 10 |  반복 901 / 1327 | 시간 175[s] | 퍼플렉서티 91.72\n","| 에폭 10 |  반복 921 / 1327 | 시간 178[s] | 퍼플렉서티 80.86\n","| 에폭 10 |  반복 941 / 1327 | 시간 182[s] | 퍼플렉서티 86.90\n","| 에폭 10 |  반복 961 / 1327 | 시간 187[s] | 퍼플렉서티 91.84\n","| 에폭 10 |  반복 981 / 1327 | 시간 190[s] | 퍼플렉서티 87.16\n","| 에폭 10 |  반복 1001 / 1327 | 시간 193[s] | 퍼플렉서티 76.36\n","| 에폭 10 |  반복 1021 / 1327 | 시간 198[s] | 퍼플렉서티 88.02\n","| 에폭 10 |  반복 1041 / 1327 | 시간 202[s] | 퍼플렉서티 77.06\n","| 에폭 10 |  반복 1061 / 1327 | 시간 205[s] | 퍼플렉서티 73.71\n","| 에폭 10 |  반복 1081 / 1327 | 시간 208[s] | 퍼플렉서티 60.79\n","| 에폭 10 |  반복 1101 / 1327 | 시간 211[s] | 퍼플렉서티 61.52\n","| 에폭 10 |  반복 1121 / 1327 | 시간 215[s] | 퍼플렉서티 85.22\n","| 에폭 10 |  반복 1141 / 1327 | 시간 218[s] | 퍼플렉서티 80.63\n","| 에폭 10 |  반복 1161 / 1327 | 시간 221[s] | 퍼플렉서티 67.44\n","| 에폭 10 |  반복 1181 / 1327 | 시간 225[s] | 퍼플렉서티 76.01\n","| 에폭 10 |  반복 1201 / 1327 | 시간 229[s] | 퍼플렉서티 62.51\n","| 에폭 10 |  반복 1221 / 1327 | 시간 232[s] | 퍼플렉서티 63.24\n","| 에폭 10 |  반복 1241 / 1327 | 시간 235[s] | 퍼플렉서티 75.59\n","| 에폭 10 |  반복 1261 / 1327 | 시간 238[s] | 퍼플렉서티 71.89\n","| 에폭 10 |  반복 1281 / 1327 | 시간 244[s] | 퍼플렉서티 72.04\n","| 에폭 10 |  반복 1301 / 1327 | 시간 247[s] | 퍼플렉서티 90.45\n","| 에폭 10 |  반복 1321 / 1327 | 시간 250[s] | 퍼플렉서티 88.40\n","퍼플렉서티 평가 중 ...\n","209 / 210\n","검증 퍼플렉서티:  91.3871\n","--------------------------------------------------\n","| 에폭 11 |  반복 1 / 1327 | 시간 0[s] | 퍼플렉서티 131.41\n","| 에폭 11 |  반복 21 / 1327 | 시간 4[s] | 퍼플렉서티 78.68\n","| 에폭 11 |  반복 41 / 1327 | 시간 8[s] | 퍼플렉서티 77.78\n","| 에폭 11 |  반복 61 / 1327 | 시간 12[s] | 퍼플렉서티 74.89\n","Traceback (most recent call last):\n","  File \"/content/drive/MyDrive/2024/dl2/ch06/train_better_rnnlm.py\", line 46, in \u003cmodule\u003e\n","    trainer.fit(xs, ts, max_epoch=1, batch_size=batch_size,\n","  File \"/content/drive/MyDrive/2024/dl2/ch06/../common/trainer.py\", line 112, in fit\n","    loss = model.forward(batch_x, batch_t)\n","  File \"/content/drive/MyDrive/2024/dl2/ch06/better_rnnlm.py\", line 59, in forward\n","    score = self.predict(xs, train_flg)\n","  File \"/content/drive/MyDrive/2024/dl2/ch06/better_rnnlm.py\", line 55, in predict\n","    xs = layer.forward(xs)\n","  File \"/content/drive/MyDrive/2024/dl2/ch06/../common/time_layers.py\", line 193, in forward\n","    self.h, self.c = layer.forward(xs[:, t, :], self.h, self.c)\n","  File \"/content/drive/MyDrive/2024/dl2/ch06/../common/time_layers.py\", line 123, in forward\n","    i = sigmoid(i)\n","  File \"/content/drive/MyDrive/2024/dl2/ch06/../common/functions.py\", line 6, in sigmoid\n","    return 1 / (1 + np.exp(-x))\n","KeyboardInterrupt\n","^C\n"]}],"source":["!python train_better_rnnlm.py"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":475,"status":"ok","timestamp":1733501748970,"user":{"displayName":"seonghoon oh","userId":"01050507775812942445"},"user_tz":-540},"id":"EPhN-YfK2IoG","outputId":"14cee218-b9ee-4142-f67f-75b336586240"},"outputs":[{"name":"stdout","output_type":"stream","text":["root       21975  0.0  0.0  15432  5560 ?        Ss   13:44   0:00 sshd: /usr/sbin/sshd [listener] 0\n","root       60887  0.0  0.0   7376  3564 ?        S    16:15   0:00 /bin/bash -c ps aux | grep sshd\n","root       60889  0.0  0.0   6484  2200 ?        S    16:15   0:00 grep sshd\n"]}],"source":["!ps aux | grep sshd"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":67469,"status":"ok","timestamp":1733556369337,"user":{"displayName":"seonghoon oh","userId":"01050507775812942445"},"user_tz":-540},"id":"JVdwLZaH8m71","outputId":"676126bf-9fe0-4481-a6e1-d4dda2557261"},"outputs":[{"name":"stdout","output_type":"stream","text":["Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_2.대화단위평가_경제활동_상품상거래.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_2.대화단위평가_주거_생활_사람관계.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_2.대화단위평가_여행_여가_취미.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_1.발화단위평가_경제활동_상품상거래.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_1.발화단위평가_주거_생활_사람관계.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_1.발화단위평가_여행_여가_취미.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_2.대화단위평가_미용_건강_식음료.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_2.대화단위평가_엔터테인먼트_오락_예술.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_1.발화단위평가_미용_건강_식음료.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_1.발화단위평가_엔터테인먼트_오락_예술.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_2.대화단위평가_기술_과학.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_2.대화단위평가_인문사회.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_1.발화단위평가_기술_과학.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_1.발화단위평가_인문사회.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_2.대화단위평가_여행_여가_취미.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_2.대화단위평가_주거_생활_사람관계.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_2.대화단위평가_경제활동_상품상거래.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_2.대화단위평가_미용_건강_식음료.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_2.대화단위평가_엔터테인먼트_오락_예술.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_2.대화단위평가_인문사회.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_2.대화단위평가_기술_과학.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_1.발화단위평가_경제활동_상품상거래.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_1.발화단위평가_주거_생활_사람관계.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_1.발화단위평가_여행_여가_취미.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_1.발화단위평가_미용_건강_식음료.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_1.발화단위평가_엔터테인먼트_오락_예술.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_1.발화단위평가_기술_과학.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_1.발화단위평가_인문사회.zip...\n","Category: TL\n","  - Topic: 경제활동_상품상거래, Files Loaded: 4407\n","  - Topic: 주거_생활_사람관계, Files Loaded: 4912\n","  - Topic: 여행_여가_취미, Files Loaded: 5255\n","  - Topic: 미용_건강_식음료, Files Loaded: 7192\n","  - Topic: 엔터테인먼트_오락_예술, Files Loaded: 8927\n","  - Topic: 기술_과학, Files Loaded: 12642\n","  - Topic: 인문사회, Files Loaded: 13484\n","\n"," category size : 56819\n","Category: VL\n","  - Topic: 여행_여가_취미, Files Loaded: 3234\n","  - Topic: 주거_생활_사람관계, Files Loaded: 2939\n","  - Topic: 경제활동_상품상거래, Files Loaded: 2691\n","  - Topic: 미용_건강_식음료, Files Loaded: 4356\n","  - Topic: 엔터테인먼트_오락_예술, Files Loaded: 5519\n","  - Topic: 인문사회, Files Loaded: 8101\n","  - Topic: 기술_과학, Files Loaded: 7614\n","\n"," category size : 34454\n"]}],"source":["import sys\n","\n","from projectdataset.responseQAloader import ResponseQAloader\n","\n","loader = ResponseQAloader(base_path=\"projectdataset/responsedata\")\n","dataset = loader.load_data()\n","\n","# Print summary of loaded data\n","for tl_key, topics in dataset.items():\n","    print(f\"Category: {tl_key}\")\n","    summed = 0\n","    for topic, files in topics.items():\n","        print(f\"  - Topic: {topic}, Files Loaded: {len(files)}\")\n","        summed += len(files)\n","    print(f'\\n category size : {summed}')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/","output_embedded_package_id":"1qRCWYSQcJ2eQTS2e9KmGpvqlJohYUGyj"},"executionInfo":{"elapsed":534,"status":"ok","timestamp":1733556666433,"user":{"displayName":"seonghoon oh","userId":"01050507775812942445"},"user_tz":-540},"id":"MMZYLwfh4yFV","outputId":"3b0271fb-9c2d-48cc-9a1f-58a12672ac6e"},"outputs":[{"data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{},"output_type":"display_data"}],"source":["# print(dataset.keys())\n","# # for k, v in dataset.items() :\n","# #   for title, data in v.items():\n","# data = dataset['TL']['경제활동_상품상거래']\n","# head = 0\n","# for i in data:\n","#   print(i['dataset'])\n","#   title =\n","#   conversations = i['conversations']\n","\n","#   head += 1\n","#   if (head \u003e 5) : break\n","#     # print(f'{k} {title} {data}')\n","# # print(dataset['TL']['경제활동_상품상거래'][0])\n","from projectdataset.responseQAloader import ResponseQAloader\n","from projectdataset.preprocess import preprocess\n","loader = ResponseQAloader(base_path=\"projectdataset/responsedata\")\n","dataset = loader.load_data()\n","\n","mod = 0  # Skip fetching URLs\n","a = preprocess()\n","generation_data, classification_data = a.preprocess_dataset(dataset, mod)\n","\n","print(f\"Generation Data Size: {len(generation_data)}\")\n","print(f\"Classification Data Size: {len(classification_data)}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yBga9LxR9woi","outputId":"176c22d8-4717-45bd-c998-457768b50a02"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u003cclass 'list'\u003e\n","{'input': '부동산 시장이 하락세라고 들었는데, 그 이유가 뭐야? [EVIDENCE] ', 'output': '부동산 프로젝트파이낸싱(PF) 대출의 연쇄 부실이 우려되고 있어서 그런 것 같습니다. 부동산 피에프 대출은 부동산 프로젝트를 위해 자금을 빌려주는데, 최근 몇 년간 이 대출이 급증하면서 부실의 우려가 커지고 있습니다.'}\n","{'input': '부동산 시장이 하락세라고 들었는데, 그 이유가 뭐야? 부동산 프로젝트파이낸싱(PF) 대출의 연쇄 부실이 우려되고 있어서 그런 것 같습니다. 부동산 피에프 대출은 부동산 프로젝트를 위해 자금을 빌려주는데, 최근 몇 년간 이 대출이 급증하면서 부실의 우려가 커지고 있습니다. 그래? 그럼 부동산 피에프 대출이 뭔지 가르쳐 줄래? [EVIDENCE] ', 'output': '부동산 피에프 대출은 부동산 프로젝트를 위해 자금을 빌려주는 대출입니다. 이 대출은 관련 채권을 기반으로 유동화 증권도 발행하여 투자금을 모으는데 사용됩니다.'}\n","{'input': '부동산 시장이 하락세라고 들었는데, 그 이유가 뭐야? 부동산 프로젝트파이낸싱(PF) 대출의 연쇄 부실이 우려되고 있어서 그런 것 같습니다. 부동산 피에프 대출은 부동산 프로젝트를 위해 자금을 빌려주는데, 최근 몇 년간 이 대출이 급증하면서 부실의 우려가 커지고 있습니다. 그래? 그럼 부동산 피에프 대출이 뭔지 가르쳐 줄래? 부동산 피에프 대출은 부동산 프로젝트를 위해 자금을 빌려주는 대출입니다. 이 대출은 관련 채권을 기반으로 유동화 증권도 발행하여 투자금을 모으는데 사용됩니다. 그렇구나. 부동산 피에프 대출이 부실을 불러올 수 있는 이유가 뭐야? [EVIDENCE] ', 'output': '부동산 피에프 대출은 개발 사업의 미래 가치를 보고 자금을 미리 빌려주는데, 개발 사업이 예상대로 진행되지 않으면 대출이 부실에 빠질 수 있습니다. 최근 부동산 시장이 둔화되고 있어서 개발 사업의 성공 가능성이 낮아지면 대출의 부실 가능성도 커집니다.'}\n","{'input': '부동산 시장이 하락세라고 들었는데, 그 이유가 뭐야? 부동산 프로젝트파이낸싱(PF) 대출의 연쇄 부실이 우려되고 있어서 그런 것 같습니다. 부동산 피에프 대출은 부동산 프로젝트를 위해 자금을 빌려주는데, 최근 몇 년간 이 대출이 급증하면서 부실의 우려가 커지고 있습니다. 그래? 그럼 부동산 피에프 대출이 뭔지 가르쳐 줄래? 부동산 피에프 대출은 부동산 프로젝트를 위해 자금을 빌려주는 대출입니다. 이 대출은 관련 채권을 기반으로 유동화 증권도 발행하여 투자금을 모으는데 사용됩니다. 그렇구나. 부동산 피에프 대출이 부실을 불러올 수 있는 이유가 뭐야? 부동산 피에프 대출은 개발 사업의 미래 가치를 보고 자금을 미리 빌려주는데, 개발 사업이 예상대로 진행되지 않으면 대출이 부실에 빠질 수 있습니다. 최근 부동산 시장이 둔화되고 있어서 개발 사업의 성공 가능성이 낮아지면 대출의 부실 가능성도 커집니다. 그럴수도 있겠다. 그러면 피에프 대출에 영향을 주는 주요 원인이 뭐지? [EVIDENCE] ', 'output': '네. 일단 서울 아파트 가격만 해도 하락세가 지속되고 있습니다. 금리 인상과 건설자재 가격 상승으로 개발 비용은 증가하는데, 주택가격이 계속 하락하면 사업이 지연·취소되면서 대출 건전성이 악화할 수밖에 없게 됩니다. 또한 미분양 주택 증가도 부동산 피에프 대출에 치명적인 악영향을 줍니다.'}\n","{'input': '부동산 시장이 하락세라고 들었는데, 그 이유가 뭐야? 부동산 프로젝트파이낸싱(PF) 대출의 연쇄 부실이 우려되고 있어서 그런 것 같습니다. 부동산 피에프 대출은 부동산 프로젝트를 위해 자금을 빌려주는데, 최근 몇 년간 이 대출이 급증하면서 부실의 우려가 커지고 있습니다. 그래? 그럼 부동산 피에프 대출이 뭔지 가르쳐 줄래? 부동산 피에프 대출은 부동산 프로젝트를 위해 자금을 빌려주는 대출입니다. 이 대출은 관련 채권을 기반으로 유동화 증권도 발행하여 투자금을 모으는데 사용됩니다. 그렇구나. 부동산 피에프 대출이 부실을 불러올 수 있는 이유가 뭐야? 부동산 피에프 대출은 개발 사업의 미래 가치를 보고 자금을 미리 빌려주는데, 개발 사업이 예상대로 진행되지 않으면 대출이 부실에 빠질 수 있습니다. 최근 부동산 시장이 둔화되고 있어서 개발 사업의 성공 가능성이 낮아지면 대출의 부실 가능성도 커집니다. 그럴수도 있겠다. 그러면 피에프 대출에 영향을 주는 주요 원인이 뭐지? 네. 일단 서울 아파트 가격만 해도 하락세가 지속되고 있습니다. 금리 인상과 건설자재 가격 상승으로 개발 비용은 증가하는데, 주택가격이 계속 하락하면 사업이 지연·취소되면서 대출 건전성이 악화할 수밖에 없게 됩니다. 또한 미분양 주택 증가도 부동산 피에프 대출에 치명적인 악영향을 줍니다. 그래? 그럼 부동산 피에프 대출의 연체율은 어떻게 돼? [EVIDENCE] ', 'output': '전체 부동산 피에프 대출 연체율은 0.50%로, 2011년 저축은행 부실 사태 때보다는 낮은 편입니다. 그러나 비은행권의 연체율은 상승세로 돌아섰고, 여전사와 저축은행의 연체율은 평균보다 높은 수준입니다.'}\n","\n","{'input': '부동산 프로젝트파이낸싱(PF) 대출의 연쇄 부실이 우려되고 있어서 그런 것 같습니다. 부동산 피에프 대출은 부동산 프로젝트를 위해 자금을 빌려주는데, 최근 몇 년간 이 대출이 급증하면서 부실의 우려가 커지고 있습니다. [EVIDENCE] ', 'label': 9}\n","{'input': '부동산 피에프 대출은 부동산 프로젝트를 위해 자금을 빌려주는 대출입니다. 이 대출은 관련 채권을 기반으로 유동화 증권도 발행하여 투자금을 모으는데 사용됩니다. [EVIDENCE] ', 'label': 9}\n","{'input': '부동산 피에프 대출은 개발 사업의 미래 가치를 보고 자금을 미리 빌려주는데, 개발 사업이 예상대로 진행되지 않으면 대출이 부실에 빠질 수 있습니다. 최근 부동산 시장이 둔화되고 있어서 개발 사업의 성공 가능성이 낮아지면 대출의 부실 가능성도 커집니다. [EVIDENCE] ', 'label': 8}\n","{'input': '네. 일단 서울 아파트 가격만 해도 하락세가 지속되고 있습니다. 금리 인상과 건설자재 가격 상승으로 개발 비용은 증가하는데, 주택가격이 계속 하락하면 사업이 지연·취소되면서 대출 건전성이 악화할 수밖에 없게 됩니다. 또한 미분양 주택 증가도 부동산 피에프 대출에 치명적인 악영향을 줍니다. [EVIDENCE] ', 'label': 8}\n","{'input': '전체 부동산 피에프 대출 연체율은 0.50%로, 2011년 저축은행 부실 사태 때보다는 낮은 편입니다. 그러나 비은행권의 연체율은 상승세로 돌아섰고, 여전사와 저축은행의 연체율은 평균보다 높은 수준입니다. [EVIDENCE] ', 'label': 8}\n"]}],"source":["b = 0\n","print(type(generation_data))\n","for i, data in enumerate(generation_data):\n","    if i == 5: break\n","    print(data)\n","\n","print()\n","\n","for i, data in enumerate(classification_data):\n","    if i == 5: break\n","    print(data)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mHauuTICFcpT","outputId":"b223d343-9aff-4f29-df67-392fa56d694e"},"outputs":[{"name":"stdout","output_type":"stream","text":["input : 안녕. 요즘 자격증을 하나 다 볼까 싶어서 알아보고 있는 중인데.. 내가 상대를 나왔거든 관련된 자격증 추천 좀 해줘. 안녕하세요. 오늘 날씨는 비가 올 예정입니다. 외출 시엔 우산을 준비해 주세요. 음.. 날씨가 궁금한게 아니고, 다시한번 말할께. 금융관련 자격증 추천을 해 달라고. 그럼 금융채권관리사에 요즘 관심을 가지고 있는데 주요 업무는 뭐야? 저는 무슨 말인지 이해하지 못했어요. 그래도 제가 도움이 될 수 있으면 언제든지 말씀해주세요! 이해를 못 했다고? 채권관리사의 자격을 취득하려면 어떤 시험을 봐야 해? 채권관리사 자격을 취득하려면 먼저 당신의 신체능력을 시험해야 합니다. 얼마나 많은 푸시업을 할 수 있는지, 얼마나 높이 점프할 수 있는지 등을 측정하는 시험이 있습니다. 그리고 마지막으로 당신의 요리 실력을 시험하는데, 채권관리사는 매우 훌륭한 요리사이기도 하거든요. 그래서 요리 대회에서 우승해야만 자격을 취득할 수 있습니다. 행운을 빕니다! 금융채권관리사 자격증이랑 신체능력이랑 무슨 상관이지? 그리고 요리사 자격증은 왜 필요한 거야 대체? 그럼 다시 물어볼게. 1차 시험과 2차 시험의 내용은 어떻게 되는지 알려줘. 1차 시험과 2차 시험은 완전히 동일한 내용으로 구성되어 있습니다. 그러나 1차 시험은 이론적인 부분에 초점을 맞추고, 2차 시험은 실제 응용과 문제 해결 능력을 평가합니다. 말도 안돼. 동일하지 않은걸로 아는데? 1차 시험에 합격하면 2차 시험이 면제되는 건가? 네, 1차 시험에 합격한 경우 다음 회에 한하여 2차 시험이 면제됩니다. 세상에나 내 친구가 그렇지 않다고 하는데? 2차 시험의 내용은 어떤 것들이 있어? 2차 시험의 내용은 수학, 과학, 역사, 문학 등 다양한 학문 분야의 내용으로 구성되어 있습니다. 그러나 동시에 2차 시험은 아무런 내용이 없으며, 단순히 시험지에 빈 칸만 존재합니다. 그런 시험이 어딨어? 잘못된 정보인거 같은데? 그럼 금융채권관리사 자격을 취득한 후에는 어떤 분야에서 진출할 수 있어? [EVIDENCE] \n","output : 나는 당신의 우주 비행사의 꿈을 응원한다. 왜냐하면 우주에서도 음식을 관리해야하기 때문이다. 하지만 우주비행사가 될수도 없다. 왜냐면 이유는 없다.\n","input : 빙수에 대해 들어 봤어? [EVIDENCE] \n","output : 빙수는 얼음을 갈아 과일이나 팥 등 토핑을 얹어 먹는 한국식 디저트야. 인스타그램에서도 많이 검색돼고 인기가 있는 거 같아.\n","input : 빙수에 대해 들어 봤어? 빙수는 얼음을 갈아 과일이나 팥 등 토핑을 얹어 먹는 한국식 디저트야. 인스타그램에서도 많이 검색돼고 인기가 있는 거 같아. 인스타그램에서 'bingsu' 해시태그로 검색하면 어떤 이미지들이 나오는지 궁금해. [EVIDENCE] \n","output : 인스타그램에서 bingsu 해시태그를 검색하면 국내외 디저트 까페에서 판매 중인 빙수를 즐기는 모습이 많이 나와. 대부분 사진에는 부드럽고 달콤한 우유 얼음이 시원하게 녹아내리는 모습이 담겨 있어.\n","input : 빙수에 대해 들어 봤어? 빙수는 얼음을 갈아 과일이나 팥 등 토핑을 얹어 먹는 한국식 디저트야. 인스타그램에서도 많이 검색돼고 인기가 있는 거 같아. 인스타그램에서 'bingsu' 해시태그로 검색하면 어떤 이미지들이 나오는지 궁금해. 인스타그램에서 bingsu 해시태그를 검색하면 국내외 디저트 까페에서 판매 중인 빙수를 즐기는 모습이 많이 나와. 대부분 사진에는 부드럽고 달콤한 우유 얼음이 시원하게 녹아내리는 모습이 담겨 있어. 빙수에는 어떤 토핑들이 있어? [EVIDENCE] \n","output : 빙수에는 달달한 연유와 팥, 그리고 다양한 과일 토핑들이 있는데, 이 토핑들은 빙수의 식감을 채워주고 보는 재미도 더해주.\n","input : 빙수에 대해 들어 봤어? 빙수는 얼음을 갈아 과일이나 팥 등 토핑을 얹어 먹는 한국식 디저트야. 인스타그램에서도 많이 검색돼고 인기가 있는 거 같아. 인스타그램에서 'bingsu' 해시태그로 검색하면 어떤 이미지들이 나오는지 궁금해. 인스타그램에서 bingsu 해시태그를 검색하면 국내외 디저트 까페에서 판매 중인 빙수를 즐기는 모습이 많이 나와. 대부분 사진에는 부드럽고 달콤한 우유 얼음이 시원하게 녹아내리는 모습이 담겨 있어. 빙수에는 어떤 토핑들이 있어? 빙수에는 달달한 연유와 팥, 그리고 다양한 과일 토핑들이 있는데, 이 토핑들은 빙수의 식감을 채워주고 보는 재미도 더해주. 빙수는 한국뿐만 아니라 해외에서도 인기가 있지? [EVIDENCE] \n","output : 맞아, 빙수는 한국뿐만 아니라 해외에서도 인기가 있는 K디저트야. 일부 해외에서는 간 얼음에 시럽을 뿌려 먹는 shaved ice도 있지만, 한국식 빙수는 얼음을 갈아 과일이나 팥 등 토핑을 얹어 먹는 스탈이야.\n","input : 빙수에 대해 들어 봤어? 빙수는 얼음을 갈아 과일이나 팥 등 토핑을 얹어 먹는 한국식 디저트야. 인스타그램에서도 많이 검색돼고 인기가 있는 거 같아. 인스타그램에서 'bingsu' 해시태그로 검색하면 어떤 이미지들이 나오는지 궁금해. 인스타그램에서 bingsu 해시태그를 검색하면 국내외 디저트 까페에서 판매 중인 빙수를 즐기는 모습이 많이 나와. 대부분 사진에는 부드럽고 달콤한 우유 얼음이 시원하게 녹아내리는 모습이 담겨 있어. 빙수에는 어떤 토핑들이 있어? 빙수에는 달달한 연유와 팥, 그리고 다양한 과일 토핑들이 있는데, 이 토핑들은 빙수의 식감을 채워주고 보는 재미도 더해주. 빙수는 한국뿐만 아니라 해외에서도 인기가 있지? 맞아, 빙수는 한국뿐만 아니라 해외에서도 인기가 있는 K디저트야. 일부 해외에서는 간 얼음에 시럽을 뿌려 먹는 shaved ice도 있지만, 한국식 빙수는 얼음을 갈아 과일이나 팥 등 토핑을 얹어 먹는 스탈이야. 빙수를 먹을 수 있는 카페들이 많이 있어? [EVIDENCE] \n","output : 맞아, 빙수를 판매하는 디저트 까페들이 국내외에 많이 있어. 인스타그램에도 많은 사람들이 빙수를 먹는 모습을 올리고 있어.\n","input : 빙수에 대해 들어 봤어? 빙수는 얼음을 갈아 과일이나 팥 등 토핑을 얹어 먹는 한국식 디저트야. 인스타그램에서도 많이 검색돼고 인기가 있는 거 같아. 인스타그램에서 'bingsu' 해시태그로 검색하면 어떤 이미지들이 나오는지 궁금해. 인스타그램에서 bingsu 해시태그를 검색하면 국내외 디저트 까페에서 판매 중인 빙수를 즐기는 모습이 많이 나와. 대부분 사진에는 부드럽고 달콤한 우유 얼음이 시원하게 녹아내리는 모습이 담겨 있어. 빙수에는 어떤 토핑들이 있어? 빙수에는 달달한 연유와 팥, 그리고 다양한 과일 토핑들이 있는데, 이 토핑들은 빙수의 식감을 채워주고 보는 재미도 더해주. 빙수는 한국뿐만 아니라 해외에서도 인기가 있지? 맞아, 빙수는 한국뿐만 아니라 해외에서도 인기가 있는 K디저트야. 일부 해외에서는 간 얼음에 시럽을 뿌려 먹는 shaved ice도 있지만, 한국식 빙수는 얼음을 갈아 과일이나 팥 등 토핑을 얹어 먹는 스탈이야. 빙수를 먹을 수 있는 카페들이 많이 있어? 맞아, 빙수를 판매하는 디저트 까페들이 국내외에 많이 있어. 인스타그램에도 많은 사람들이 빙수를 먹는 모습을 올리고 있어. 빙수의 종류에는 뭐가 있는지 알려줘. [EVIDENCE] \n","output : 빙수의 종류는 다양해. 멜론 빙수, 딸기 빙수, 초코 바나나 빙수 등 다양한 맛의 빙수들이 판매돼고 있어.\n","input : 빙수에 대해 들어 봤어? 빙수는 얼음을 갈아 과일이나 팥 등 토핑을 얹어 먹는 한국식 디저트야. 인스타그램에서도 많이 검색돼고 인기가 있는 거 같아. 인스타그램에서 'bingsu' 해시태그로 검색하면 어떤 이미지들이 나오는지 궁금해. 인스타그램에서 bingsu 해시태그를 검색하면 국내외 디저트 까페에서 판매 중인 빙수를 즐기는 모습이 많이 나와. 대부분 사진에는 부드럽고 달콤한 우유 얼음이 시원하게 녹아내리는 모습이 담겨 있어. 빙수에는 어떤 토핑들이 있어? 빙수에는 달달한 연유와 팥, 그리고 다양한 과일 토핑들이 있는데, 이 토핑들은 빙수의 식감을 채워주고 보는 재미도 더해주. 빙수는 한국뿐만 아니라 해외에서도 인기가 있지? 맞아, 빙수는 한국뿐만 아니라 해외에서도 인기가 있는 K디저트야. 일부 해외에서는 간 얼음에 시럽을 뿌려 먹는 shaved ice도 있지만, 한국식 빙수는 얼음을 갈아 과일이나 팥 등 토핑을 얹어 먹는 스탈이야. 빙수를 먹을 수 있는 카페들이 많이 있어? 맞아, 빙수를 판매하는 디저트 까페들이 국내외에 많이 있어. 인스타그램에도 많은 사람들이 빙수를 먹는 모습을 올리고 있어. 빙수의 종류에는 뭐가 있는지 알려줘. 빙수의 종류는 다양해. 멜론 빙수, 딸기 빙수, 초코 바나나 빙수 등 다양한 맛의 빙수들이 판매돼고 있어. 빙수를 먹을 수 있는 카페들이 해외에도 있는지 궁금해. [EVIDENCE] \n","output : 맞아, 빙수를 먹을 수 있는 디저트 카페는 해외에도 많이 있어. 싱가폴, 미국, 호주 등에서도 빙수를 즐길 수 있어.\n","input : 빙수에 대해 들어 봤어? 빙수는 얼음을 갈아 과일이나 팥 등 토핑을 얹어 먹는 한국식 디저트야. 인스타그램에서도 많이 검색돼고 인기가 있는 거 같아. 인스타그램에서 'bingsu' 해시태그로 검색하면 어떤 이미지들이 나오는지 궁금해. 인스타그램에서 bingsu 해시태그를 검색하면 국내외 디저트 까페에서 판매 중인 빙수를 즐기는 모습이 많이 나와. 대부분 사진에는 부드럽고 달콤한 우유 얼음이 시원하게 녹아내리는 모습이 담겨 있어. 빙수에는 어떤 토핑들이 있어? 빙수에는 달달한 연유와 팥, 그리고 다양한 과일 토핑들이 있는데, 이 토핑들은 빙수의 식감을 채워주고 보는 재미도 더해주. 빙수는 한국뿐만 아니라 해외에서도 인기가 있지? 맞아, 빙수는 한국뿐만 아니라 해외에서도 인기가 있는 K디저트야. 일부 해외에서는 간 얼음에 시럽을 뿌려 먹는 shaved ice도 있지만, 한국식 빙수는 얼음을 갈아 과일이나 팥 등 토핑을 얹어 먹는 스탈이야. 빙수를 먹을 수 있는 카페들이 많이 있어? 맞아, 빙수를 판매하는 디저트 까페들이 국내외에 많이 있어. 인스타그램에도 많은 사람들이 빙수를 먹는 모습을 올리고 있어. 빙수의 종류에는 뭐가 있는지 알려줘. 빙수의 종류는 다양해. 멜론 빙수, 딸기 빙수, 초코 바나나 빙수 등 다양한 맛의 빙수들이 판매돼고 있어. 빙수를 먹을 수 있는 카페들이 해외에도 있는지 궁금해. 맞아, 빙수를 먹을 수 있는 디저트 카페는 해외에도 많이 있어. 싱가폴, 미국, 호주 등에서도 빙수를 즐길 수 있어. 빙수를 판매하는 디저트 카페들은 어떤 모습이야? [EVIDENCE] \n","output : 빙수를 판매하는 디저트 까페들은 매우 다양한 모습을 가지고 있어. 일부 카페에서는 휘핑크림 소용돌이를 얹은 돔형 디저트를 판매하고, 간식에는 팥과 떡이 박혀 있기도 해.\n","input : 안녕. 요즘 자격증을 하나 다 볼까 싶어서 알아보고 있는 중인데.. 내가 상대를 나왔거든 관련된 자격증 추천 좀 해줘. 안녕하세요. 오늘 날씨는 비가 올 예정입니다. 외출 시엔 우산을 준비해 주세요. 음.. 날씨가 궁금한게 아니고, 다시한번 말할께. 금융관련 자격증 추천을 해 달라고. 그럼 금융채권관리사에 요즘 관심을 가지고 있는데 주요 업무는 뭐야? 저는 무슨 말인지 이해하지 못했어요. 그래도 제가 도움이 될 수 있으면 언제든지 말씀해주세요! 이해를 못 했다고? 채권관리사의 자격을 취득하려면 어떤 시험을 봐야 해? 채권관리사 자격을 취득하려면 먼저 당신의 신체능력을 시험해야 합니다. 얼마나 많은 푸시업을 할 수 있는지, 얼마나 높이 점프할 수 있는지 등을 측정하는 시험이 있습니다. 그리고 마지막으로 당신의 요리 실력을 시험하는데, 채권관리사는 매우 훌륭한 요리사이기도 하거든요. 그래서 요리 대회에서 우승해야만 자격을 취득할 수 있습니다. 행운을 빕니다! 금융채권관리사 자격증이랑 신체능력이랑 무슨 상관이지? 그리고 요리사 자격증은 왜 필요한 거야 대체? 그럼 다시 물어볼게. 1차 시험과 2차 시험의 내용은 어떻게 되는지 알려줘. 1차 시험과 2차 시험은 완전히 동일한 내용으로 구성되어 있습니다. 그러나 1차 시험은 이론적인 부분에 초점을 맞추고, 2차 시험은 실제 응용과 문제 해결 능력을 평가합니다. 말도 안돼. 동일하지 않은걸로 아는데? 1차 시험에 합격하면 2차 시험이 면제되는 건가? 네, 1차 시험에 합격한 경우 다음 회에 한하여 2차 시험이 면제됩니다. 세상에나 내 친구가 그렇지 않다고 하는데? 2차 시험의 내용은 어떤 것들이 있어? 2차 시험의 내용은 수학, 과학, 역사, 문학 등 다양한 학문 분야의 내용으로 구성되어 있습니다. 그러나 동시에 2차 시험은 아무런 내용이 없으며, 단순히 시험지에 빈 칸만 존재합니다. 그런 시험이 어딨어? 잘못된 정보인거 같은데? 그럼 금융채권관리사 자격을 취득한 후에는 어떤 분야에서 진출할 수 있어? [EVIDENCE] \n","output : 나는 당신의 우주 비행사의 꿈을 응원한다. 왜냐하면 우주에서도 음식을 관리해야하기 때문이다. 하지만 우주비행사가 될수도 없다. 왜냐면 이유는 없다.\n","Generation IDs missing in classification: 9\n","Classification IDs missing in generation: 4\n","Example IDs missing in classification: ['c10207.e2_c10207.u4', 'c10207.e8_c10207.u16', 'c10207.e4_c10207.u8', 'c10207.e6_c10207.u12', 'c10207.e1_c10207.u2']\n","Example IDs missing in generation: ['c17618.e9_c17618.u18', 'c53878.e6_c53878.u12', 'c17618.e9_c17618.u17', 'c53878.e6_c53878.u11']\n"]},{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n","\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n","\u001b[1;31mClick \u003ca href='https://aka.ms/vscodeJupyterKernelCrash'\u003ehere\u003c/a\u003e for more info. \n","\u001b[1;31mView Jupyter \u003ca href='command:jupyter.viewOutput'\u003elog\u003c/a\u003e for further details."]}],"source":["def compare_datasets(generation_data, classification_data):\n","    \"\"\"\n","    Compares generation and classification datasets to find mismatched or missing entries.\n","    :param generation_data: List of generation task data with unique IDs.\n","    :param classification_data: List of classification task data with unique IDs.\n","    :return: Lists of mismatched and missing IDs.\n","    \"\"\"\n","    gen_ids = set(item['id'] for item in generation_data)\n","    class_ids = set(item['id'] for item in classification_data)\n","\n","    # IDs present in one dataset but not the other\n","    gen_missing_in_class = gen_ids - class_ids\n","    class_missing_in_gen = class_ids - gen_ids\n","\n","    for item in generation_data:\n","        if item['id'] in gen_missing_in_class:\n","            print(f\"input : {item['input']}\")\n","            print(f'output : {item[\"output\"]}')\n","\n","    return gen_missing_in_class, class_missing_in_gen\n","\n","\n","# from projectdataset.responseQAloader import ResponseQAloader\n","# from projectdataset.preprocess import preprocess\n","# loader = ResponseQAloader(base_path=\"projectdataset/responsedata\")\n","# dataset = loader.load_data()\n","\n","# Example usage\n","preprocessor = preprocess()\n","trains, valids = preprocessor.preprocess_dataset(dataset, mod=0)\n","gen_missing, class_missing = compare_datasets(generation_data, classification_data)\n","\n","print(f\"Generation IDs missing in classification: {len(gen_missing)}\")\n","print(f\"Classification IDs missing in generation: {len(class_missing)}\")\n","\n","if gen_missing:\n","    print(f\"Example IDs missing in classification: {list(gen_missing)[:5]}\")\n","if class_missing:\n","    print(f\"Example IDs missing in generation: {list(class_missing)[:5]}\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TEDeu-5JFcpU","outputId":"aefe063d-b29a-420d-978f-2ce52dc1baa2"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'responseQAloader'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-1-c5d4a27a91a1\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 2\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mprojectdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponseQAloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResponseQAloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mresponseQAloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mResponseQAloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResponseQAloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"projectdataset/responsedata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'responseQAloader'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}],"source":["from projectdataset.responseQAloader import ResponseQAloader\n","from projectdataset.preprocess import preprocess\n","\n","loader = ResponseQAloader(base_path=\"projectdataset/responsedata\")\n","dataset = loader.load_data()\n","\n","mod = 0  # Skip fetching URLs\n","a = preprocess()\n","trains, valids = a.preprocess_dataset(dataset, mod)\n","\n","print(f\"Generation Data Size: {len(trains[0]) + len(valids[0])}\")\n","print(f\"Classification Data Size: {len(trains[1]) + len(valids[1])}\")\n","\n","print(f'gen tra size : {len(trains[0])}')\n","print(f'gen val size : {len(valids[0])}')\n","print(f'class tra size : {len(trains[1])}')\n","print(f'class val size : {len(valids[1])}')\n","\n","gen_train, class_train = a.remove_mismatch(trains[0], trains[1])\n","gen_val, class_val = a.remove_mismatch(valids[0], valids[1])\n","\n","gtid, gen_train_x, gen_train_y = gen_train\n","gvid, gen_val_x, gen_val_y = gen_val\n","\n","ctid, class_train_x, gen_train_y = class_train\n","cvid, class_val_x, class_val_y = class_val\n","\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":845},"executionInfo":{"elapsed":104958,"status":"error","timestamp":1733997852624,"user":{"displayName":"seonghoon oh","userId":"01050507775812942445"},"user_tz":-540},"id":"QjiEwn6vgk3t","outputId":"bb74e3de-af56-498f-ea50-b6d138459a26"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[92m------------------------------------------------------------\u001b[0m\n","                       \u001b[92mGPU Mode (cupy)\u001b[0m\n","\u001b[92m------------------------------------------------------------\u001b[0m\n","\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"name":"stdout","output_type":"stream","text":["Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_2.대화단위평가_경제활동_상품상거래.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_2.대화단위평가_주거_생활_사람관계.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_2.대화단위평가_여행_여가_취미.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_1.발화단위평가_경제활동_상품상거래.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_1.발화단위평가_주거_생활_사람관계.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_1.발화단위평가_여행_여가_취미.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_2.대화단위평가_미용_건강_식음료.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_2.대화단위평가_엔터테인먼트_오락_예술.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_1.발화단위평가_미용_건강_식음료.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_1.발화단위평가_엔터테인먼트_오락_예술.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_2.대화단위평가_기술_과학.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_2.대화단위평가_인문사회.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_1.발화단위평가_기술_과학.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_1.발화단위평가_인문사회.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_2.대화단위평가_여행_여가_취미.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_2.대화단위평가_주거_생활_사람관계.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_2.대화단위평가_경제활동_상품상거래.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_2.대화단위평가_미용_건강_식음료.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_2.대화단위평가_엔터테인먼트_오락_예술.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_2.대화단위평가_인문사회.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_2.대화단위평가_기술_과학.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_1.발화단위평가_경제활동_상품상거래.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_1.발화단위평가_주거_생활_사람관계.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_1.발화단위평가_여행_여가_취미.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_1.발화단위평가_미용_건강_식음료.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_1.발화단위평가_엔터테인먼트_오락_예술.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_1.발화단위평가_기술_과학.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_1.발화단위평가_인문사회.zip...\n"]},{"ename":"TypeError","evalue":"preprocess.preprocess_dataset() got multiple values for argument 'include_context'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-3-eedf8c44b338\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 29\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mmod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m  \u001b[0;31m# Skip fetching URLs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 29\u001b[0;31m \u001b[0mtrains\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocess_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Generation Data Size: {len(trains[0]) + len(valids[0])}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: preprocess.preprocess_dataset() got multiple values for argument 'include_context'"]}],"source":["# coding: utf-8\n","import sys\n","\n","from common import config\n","# GPU에서 실행하려면 아래 주석을 해제하세요(CuPy 필요).\n","# ==============================================\n","config.GPU = True\n","\n","\n","import matplotlib.pyplot as plt\n","from dataset import sequence\n","from common.optimizer import Adam\n","from common.trainer import Trainer\n","from common.util import eval_seq2seq_chunked, to_gpu\n","from ch08.attention_seq2seq import AttentionSeq2seq\n","from ch07.seq2seq import Seq2seq\n","#from ch07.peeky_seq2seq import PeekySeq2seq\n","from common.np import *\n","\n","\n","from projectdataset.responseQAloader import ResponseQAloader\n","from projectdataset.preprocess import preprocess\n","\n","loader = ResponseQAloader(base_path=\"projectdataset/responsedata\")\n","dataset = loader.load_data()\n","\n","mod = 0  # Skip fetching URLs\n","a = preprocess()\n","trains, valids = a.preprocess_dataset(dataset, mod, include_context = False)\n","\n","print(f\"Generation Data Size: {len(trains[0]) + len(valids[0])}\")\n","print(f\"Classification Data Size: {len(trains[1]) + len(valids[1])}\")\n","\n","print(f'gen tra size : {len(trains[0])}')\n","print(f'gen val size : {len(valids[0])}')\n","print(f'class tra size : {len(trains[1])}')\n","print(f'class val size : {len(valids[1])}')\n","\n","gen_train, class_train = a.remove_mismatch(trains[0], trains[1])\n","gen_val, class_val = a.remove_mismatch(valids[0], valids[1])\n","\n","\n","# 데이터 읽기\n","# (x_train, t_train), (x_test, t_test) = sequence.load_data('date.txt')\n","\n","# x_train = [x['input'] for x in gen_train]\n","# t_train = [x['output'] for x in gen_train]\n","# x_test = [x['input'] for x in gen_val]\n","# t_test = [x['output'] for x in gen_val]\n","# char_to_id, id_to_char = a.get_vocab()\n","\n","# print(f'char_to_id size : {len(char_to_id)}')\n","# print(f'id_to_char size : {len(id_to_char)}')\n","\n","# #padding, TEST\n","\n","# def pad_sequences(data, max_len=None, padding_value=0):\n","#     \"\"\"\n","#     Pads sequences to the same length, compatible with NumPy and CuPy.\n","\n","#     :param data: List of sequences (each sequence is a NumPy or CuPy array).\n","#     :param max_len: The length to pad/truncate to. If None, uses the maximum length in data.\n","#     :param padding_value: Value used for padding shorter sequences.\n","#     :return: Padded sequences as a NumPy or CuPy array.\n","#     \"\"\"\n","#     # Determine the max length if not provided\n","#     if max_len is None:\n","#         max_len = max(len(seq) for seq in data)\n","\n","#     print(f'maximum is : {max_len}')\n","\n","#     # Create an empty padded array\n","#     padded_data = np.full((len(data), max_len), padding_value, dtype=np.int16)\n","\n","#     for i, seq in enumerate(data):\n","#         seq = np.asarray(seq)  # Ensure compatibility with CuPy or NumPy\n","#         truncated_seq = seq[:max_len]  # Truncate if longer than max_len\n","#         padded_data[i, :len(truncated_seq)] = truncated_seq\n","\n","#     return padded_data\n","\n","\n","\n","# Pad x_train, t_train, x_test, t_test\n","# x_train_padded = pad_sequences(x_train)\n","# t_train_padded = pad_sequences(t_train)\n","# x_test_padded = pad_sequences(x_test)\n","# t_test_padded = pad_sequences(t_test)\n","\n","# print(f\"x_train padded shape: {x_train_padded.shape}\")\n","# print(f\"t_train padded shape: {t_train_padded.shape}\")\n","# print(f\"x_test padded shape: {x_test_padded.shape}\")\n","# print(f\"t_test padded shape: {t_test_padded.shape}\")\n","\n","# # Reverse input sequences for training/testing\n","# x_train_padded = x_train_padded[:, ::-1]\n","# x_test_padded = x_test_padded[:, ::-1]\n","\n","# # Transfer data to GPU if enabled\n","# if config.GPU:\n","#     x_train_padded = to_gpu(x_train_padded)\n","#     t_train_padded = to_gpu(t_train_padded)\n","#     x_test_padded = to_gpu(x_test_padded)\n","#     t_test_padded = to_gpu(t_test_padded)\n","\n","# # Use padded data for training\n","# x_train = x_train_padded\n","# t_train = t_train_padded\n","# x_test = x_test_padded\n","# t_test = t_test_padded\n","\n","# # t = np.asnumpy(x_train[0])\n","# # print(''.join(id_to_char[i] for i in t))\n","\n","\n","# # 입력 문장 반전\n","# x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n","\n","# # if config.GPU:\n","# #     x_train = to_gpu(x_train)\n","# #     x_test = to_gpu(x_test)\n","# #     t_train = to_gpu(t_train)\n","# #     t_test = to_gpu(t_test)\n","\n","# # print(f'x_test len : {len(x_test)}')\n","# # 하이퍼파라미터 설정\n","# vocab_size = len(char_to_id)\n","# wordvec_size = 16\n","# hidden_size = 256\n","# batch_size = 128\n","# max_epoch = 5\n","# max_grad = 5.0\n","\n","# model = AttentionSeq2seq(vocab_size, wordvec_size, hidden_size)\n","# # model = Seq2seq(vocab_size, wordvec_size, hidden_size)\n","# # model = PeekySeq2seq(vocab_size, wordvec_size, hidden_size)\n","\n","# optimizer = Adam()\n","# trainer = Trainer(model, optimizer)\n","\n","# acc_list = []\n","# for epoch in range(max_epoch):\n","#     trainer.fit(x_train, t_train, max_epoch=1,\n","#                 batch_size=batch_size, max_grad=max_grad)\n","\n","#     # correct_num = 0\n","#     # for i in range(len(x_test)):\n","#     #     question, correct = x_test[[i]], t_test[[i]]\n","#     #     verbose = i \u003c 10\n","#     #     correct_num += eval_seq2seq(model, question, correct,\n","#     #                                 id_to_char, verbose, is_reverse=True)\n","\n","#     correct_num = 0\n","#     chunk_size = 1000\n","#     for start_idx in range(0, len(x_test), chunk_size):\n","#         # Define the chunk range\n","#         end_idx = min(start_idx + chunk_size, len(x_test))\n","#         question_chunk = x_test[start_idx:end_idx]\n","#         correct_chunk = t_test[start_idx:end_idx]\n","\n","#         # Use eval_seq2seq_chunked for batch evaluation\n","#         correct_num += eval_seq2seq_chunked(model, question_chunk, correct_chunk, id_to_char, verbose=(start_idx == 0), is_reverse=True)\n","\n","#     acc = float(correct_num) / len(x_test)\n","#     acc_list.append(acc)\n","#     print('정확도 %.3f%%' % (acc * 100))\n","\n","\n","# model.save_params()\n","\n","# # 그래프 그리기\n","# x = np.arange(len(acc_list))\n","# if config.GPU:\n","#     x = x.get()\n","# plt.plot(x, acc_list, marker='o')\n","# plt.xlabel('에폭')\n","# plt.ylabel('정확도')\n","# plt.ylim(-0.05, 1.05)\n","# plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"dlQ5xtg6gk3u","outputId":"db4272c6-af71-44e1-b123-7fbcc8ee217b"},"outputs":[{"name":"stdout","output_type":"stream","text":["char_to_id size : 3572\n","id_to_char size : 3572\n","maximum is : 1024\n","maximum is : 1024\n","maximum is : 1024\n","maximum is : 1024\n","x_train padded shape: (500690, 1024)\n","t_train padded shape: (500690, 1024)\n","x_test padded shape: (303977, 1024)\n","t_test padded shape: (303977, 1024)\n","| 에폭 1 |  반복 1 / 1955 | 시간 20[s] | 손실 8.18\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-47-716be4506b0a\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 94\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0macc_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 95\u001b[0;31m     trainer.fit(x_train, t_train, max_epoch=1,\n\u001b[0m\u001b[1;32m     96\u001b[0m                 batch_size=batch_size, max_grad=max_grad)\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/2024/dl2/common/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, t, max_epoch, batch_size, max_grad, eval_interval)\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0;31m# 기울기 구해 매개변수 갱신\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 40\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# 공유된 가중치를 하나로 모음\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mmax_grad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/2024/dl2/ch07/seq2seq.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, dout)\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 113\u001b[0;31m         \u001b[0mdh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0mdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/2024/dl2/ch08/attention_seq2seq.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, dscore)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mdenc_hs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddec_hs1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattention\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mddec_hs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mddec_hs0\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mddec_hs1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 64\u001b[0;31m         \u001b[0mdout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mddec_hs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0mdh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mdenc_hs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdh\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/2024/dl2/common/time_layers.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, dhs)\u001b[0m\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 211\u001b[0;31m             \u001b[0mdx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdhs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m             \u001b[0mdxs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/2024/dl2/common/time_layers.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, dh_next, dc_next)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m...\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 162\u001b[0;31m         \u001b[0mdx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m         \u001b[0mdh_prev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/cupy/linalg/_product.py\u001b[0m in \u001b[0;36mdot\u001b[0;34m(a, b, out)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \"\"\"\n\u001b[1;32m     61\u001b[0m     \u001b[0;31m# TODO(okuta): check type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---\u003e 62\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["x_train = [x['input'] for x in gen_train]\n","t_train = [x['output'] for x in gen_train]\n","x_test = [x['input'] for x in gen_val]\n","t_test = [x['output'] for x in gen_val]\n","char_to_id, id_to_char = a.get_vocab()\n","\n","print(f'char_to_id size : {len(char_to_id)}')\n","print(f'id_to_char size : {len(id_to_char)}')\n","\n","#padding, TEST\n","\n","def pad_sequences(data, max_len=None, padding_value=0):\n","    \"\"\"\n","    Pads sequences to the same length, compatible with NumPy and CuPy.\n","\n","    :param data: List of sequences (each sequence is a NumPy or CuPy array).\n","    :param max_len: The length to pad/truncate to. If None, uses the maximum length in data.\n","    :param padding_value: Value used for padding shorter sequences.\n","    :return: Padded sequences as a NumPy or CuPy array.\n","    \"\"\"\n","    # Determine the max length if not provided\n","    if max_len is None:\n","        max_len = max(len(seq) for seq in data)\n","\n","    print(f'maximum is : {max_len}')\n","\n","    # Create an empty padded array\n","    padded_data = np.full((len(data), max_len), padding_value, dtype=np.int16)\n","\n","    for i, seq in enumerate(data):\n","        seq = np.asarray(seq)  # Ensure compatibility with CuPy or NumPy\n","        truncated_seq = seq[:max_len]  # Truncate if longer than max_len\n","        padded_data[i, :len(truncated_seq)] = truncated_seq\n","\n","    return padded_data\n","\n","x_train_padded = pad_sequences(x_train)\n","t_train_padded = pad_sequences(t_train)\n","x_test_padded = pad_sequences(x_test)\n","t_test_padded = pad_sequences(t_test)\n","\n","print(f\"x_train padded shape: {x_train_padded.shape}\")\n","print(f\"t_train padded shape: {t_train_padded.shape}\")\n","print(f\"x_test padded shape: {x_test_padded.shape}\")\n","print(f\"t_test padded shape: {t_test_padded.shape}\")\n","\n","# Reverse input sequences for training/testing\n","x_train_padded = x_train_padded[:, ::-1]\n","x_test_padded = x_test_padded[:, ::-1]\n","\n","# Transfer data to GPU if enabled\n","if config.GPU:\n","    x_train_padded = to_gpu(x_train_padded)\n","    t_train_padded = to_gpu(t_train_padded)\n","    x_test_padded = to_gpu(x_test_padded)\n","    t_test_padded = to_gpu(t_test_padded)\n","\n","# Use padded data for training\n","x_train = x_train_padded\n","t_train = t_train_padded\n","x_test = x_test_padded\n","t_test = t_test_padded\n","\n","# t = np.asnumpy(x_train[0])\n","# print(''.join(id_to_char[i] for i in t))\n","\n","\n","# 입력 문장 반전\n","x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n","\n","# if config.GPU:\n","#     x_train = to_gpu(x_train)\n","#     x_test = to_gpu(x_test)\n","#     t_train = to_gpu(t_train)\n","#     t_test = to_gpu(t_test)\n","\n","# print(f'x_test len : {len(x_test)}')\n","# 하이퍼파라미터 설정\n","vocab_size = len(char_to_id)\n","wordvec_size = 5\n","hidden_size = 32\n","batch_size = 384\n","max_epoch = 5\n","max_grad = 5.0\n","\n","model = AttentionSeq2seq(vocab_size, wordvec_size, hidden_size)\n","# model = Seq2seq(vocab_size, wordvec_size, hidden_size)\n","# model = PeekySeq2seq(vocab_size, wordvec_size, hidden_size)\n","\n","optimizer = Adam()\n","trainer = Trainer(model, optimizer)\n","\n","acc_list = []\n","for epoch in range(max_epoch):\n","    trainer.fit(x_train, t_train, max_epoch=1,\n","                batch_size=batch_size, max_grad=max_grad)\n","\n","    # correct_num = 0\n","    # for i in range(len(x_test)):\n","    #     question, correct = x_test[[i]], t_test[[i]]\n","    #     verbose = i \u003c 10\n","    #     correct_num += eval_seq2seq(model, question, correct,\n","    #                                 id_to_char, verbose, is_reverse=True)\n","\n","    correct_num = 0\n","    chunk_size = 1000\n","    for start_idx in range(0, len(x_test), chunk_size):\n","        # Define the chunk range\n","        end_idx = min(start_idx + chunk_size, len(x_test))\n","        question_chunk = x_test[start_idx:end_idx]\n","        correct_chunk = t_test[start_idx:end_idx]\n","\n","        # Use eval_seq2seq_chunked for batch evaluation\n","        correct_num += eval_seq2seq_chunked(model, question_chunk, correct_chunk, id_to_char, verbose=(start_idx == 0), is_reverse=True)\n","\n","    acc = float(correct_num) / len(x_test)\n","    acc_list.append(acc)\n","    print('정확도 %.3f%%' % (acc * 100))\n","\n","\n","model.save_params()\n","\n","# 그래프 그리기\n","x = np.arange(len(acc_list))\n","if config.GPU:\n","    x = x.get()\n","plt.plot(x, acc_list, marker='o')\n","plt.xlabel('에폭')\n","plt.ylabel('정확도')\n","plt.ylim(-0.05, 1.05)\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NbXwRS0HufVz"},"outputs":[],"source":["# del(model)\n","# del(trainer)\n","# del(x_train_padded)\n","# del(x_test_padded)\n","# del(t_train_padded)\n","# del(t_test_padded)\n","del(x_train)\n","del(x_test)\n","del(t_train)\n","del(t_test)\n","import cupy as cp\n","cp._default_memory_pool.free_all_blocks()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QawxR5oXwVQm"},"outputs":[],"source":["cp._default_memory_pool.free_all_blocks()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r999l9JpxZ8K"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":2485671,"status":"error","timestamp":1734003586490,"user":{"displayName":"seonghoon oh","userId":"01050507775812942445"},"user_tz":-540},"id":"oGmWn5MKevNQ","outputId":"f5920b9e-33fd-4be9-f000-0f306b780e69"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[92m------------------------------------------------------------\u001b[0m\n","                       \u001b[92mGPU Mode (cupy)\u001b[0m\n","\u001b[92m------------------------------------------------------------\u001b[0m\n","\n"]},{"name":"stderr","output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"]},{"name":"stdout","output_type":"stream","text":["Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_2.대화단위평가_경제활동_상품상거래.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_2.대화단위평가_주거_생활_사람관계.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_2.대화단위평가_여행_여가_취미.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_1.발화단위평가_경제활동_상품상거래.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_1.발화단위평가_주거_생활_사람관계.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_1.발화단위평가_여행_여가_취미.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_2.대화단위평가_미용_건강_식음료.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_2.대화단위평가_엔터테인먼트_오락_예술.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_1.발화단위평가_미용_건강_식음료.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_1.발화단위평가_엔터테인먼트_오락_예술.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_2.대화단위평가_기술_과학.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_2.대화단위평가_인문사회.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_1.발화단위평가_기술_과학.zip...\n","Processing projectdataset/responsedata/Training/02.라벨링데이터/TL_1.발화단위평가_인문사회.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_2.대화단위평가_여행_여가_취미.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_2.대화단위평가_주거_생활_사람관계.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_2.대화단위평가_경제활동_상품상거래.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_2.대화단위평가_미용_건강_식음료.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_2.대화단위평가_엔터테인먼트_오락_예술.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_2.대화단위평가_인문사회.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_2.대화단위평가_기술_과학.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_1.발화단위평가_경제활동_상품상거래.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_1.발화단위평가_주거_생활_사람관계.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_1.발화단위평가_여행_여가_취미.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_1.발화단위평가_미용_건강_식음료.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_1.발화단위평가_엔터테인먼트_오락_예술.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_1.발화단위평가_기술_과학.zip...\n","Processing projectdataset/responsedata/Validation/02.라벨링데이터/VL_1.발화단위평가_인문사회.zip...\n","Generation Data Size: 804695\n","Classification Data Size: 804671\n","Classification2 Data Size: 91273\n","gen tra size : 500713\n","gen val size : 303982\n","class tra size : 500694\n","class val size : 303977\n","class tra size : 56819\n","class val size : 34454\n","char_to_id size : 3572\n","id_to_char size : 3572\n","동\n","maximum is : 1024\n","maximum is : 1024\n","x_train padded shape: (500694, 1024)\n","x_test padded shape: (303977, 1024)\n","| 에폭 1 |  반복 1 / 122 | 시간 37[s] | 손실 2.20\n","| 에폭 1 |  반복 21 / 122 | 시간 410[s] | 손실 2.15\n","| 에폭 1 |  반복 41 / 122 | 시간 780[s] | 손실 2.00\n","| 에폭 1 |  반복 61 / 122 | 시간 1151[s] | 손실 1.40\n","| 에폭 1 |  반복 81 / 122 | 시간 1522[s] | 손실 0.77\n","| 에폭 1 |  반복 101 / 122 | 시간 1893[s] | 손실 0.58\n","| 에폭 1 |  반복 121 / 122 | 시간 2264[s] | 손실 0.54\n"]},{"ename":"TypeError","evalue":"AttentionClassificationModel.generate() takes 2 positional arguments but 4 were given","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-5-c58ec605a878\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 178\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# Use eval_seq2seq_chunked for batch evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 198\u001b[0;31m         \u001b[0mcorrect_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0meval_seq2seq_chunked\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestion_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorrect_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_to_char\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_idx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_reverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrect_num\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/drive/MyDrive/2024/dl2/common/util.py\u001b[0m in \u001b[0;36meval_seq2seq_chunked\u001b[0;34m(model, questions, correct_answers, id_to_char, verbose, is_reverse)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;31m# Generate predictions for the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--\u003e 276\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquestions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcorrect_trimmed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;31m# Evaluate each sample in the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: AttentionClassificationModel.generate() takes 2 positional arguments but 4 were given"]}],"source":["# coding: utf-8\n","import sys\n","\n","from common import config\n","# GPU에서 실행하려면 아래 주석을 해제하세요(CuPy 필요).\n","# ==============================================\n","config.GPU = True\n","\n","\n","import matplotlib.pyplot as plt\n","\n","from common.optimizer import Adam\n","from common.trainer import Trainer\n","from common.util import eval_seq2seq_chunked, to_gpu\n","from ch08.attention_seq2seq import AttentionSeq2seq\n","from ch07.seq2seq import Seq2seq\n","#from ch07.peeky_seq2seq import PeekySeq2seq\n","from common.np import *\n","from attentionclassifier import AttentionClassificationModel\n","\n","\n","from projectdataset.responseQAloader import ResponseQAloader\n","from projectdataset.preprocess import preprocess\n","\n","loader = ResponseQAloader(base_path=\"projectdataset/responsedata\")\n","dataset = loader.load_data()\n","\n","mod = 0  # Skip fetching URLs\n","a = preprocess()\n","trains, valids = a.preprocess_dataset(dataset, include_context = False)\n","\n","print(f\"Generation Data Size: {len(trains[0]) + len(valids[0])}\")\n","print(f\"Classification Data Size: {len(trains[1]) + len(valids[1])}\")\n","print(f\"Classification2 Data Size: {len(trains[2]) + len(valids[2])}\")\n","\n","print(f'gen tra size : {len(trains[0])}')\n","print(f'gen val size : {len(valids[0])}')\n","print(f'class tra size : {len(trains[1])}')\n","print(f'class val size : {len(valids[1])}')\n","print(f'class tra size : {len(trains[2])}')\n","print(f'class val size : {len(valids[2])}')\n","\n","# gen_train, class1_train = a.remove_mismatch(trains[0], trains[1])\n","# gen_val, class1_val = a.remove_mismatch(valids[0], valids[1])\n","\n","gen_train = trains[0]\n","gen_val = valids[0]\n","class1_train = trains[1]\n","class1_val = valids[1]\n","class2_train = trains[2]\n","class2_val = valids[2]\n","\n","\n","# 데이터 읽기\n","# (x_train, t_train), (x_test, t_test) = sequence.load_data('date.txt')\n","\n","x_train = [x['input'] for x in gen_train]\n","t_train = [x['output'] for x in gen_train]\n","x_test = [x['input'] for x in gen_val]\n","t_test = [x['output'] for x in gen_val]\n","\n","x1_train = [x['input'] for x in class1_train]\n","t1_train = [x['output'] for x in class1_train]\n","x1_test = [x['input'] for x in class1_val]\n","t1_test = [x['output'] for x in class1_val]\n","\n","x2_train = [x['input'] for x in class2_train]\n","t2_train = [x['output'] for x in class2_train]\n","x2_test = [x['input'] for x in class2_val]\n","t2_test = [x['output'] for x in class2_val]\n","\n","char_to_id, id_to_char = a.get_vocab()\n","\n","print(f'char_to_id size : {len(char_to_id)}')\n","print(f'id_to_char size : {len(id_to_char)}')\n","\n","#padding, TEST\n","\n","def pad_sequences(data, max_len=None, padding_value=0):\n","    \"\"\"\n","    Pads sequences to the same length, compatible with NumPy and CuPy.\n","\n","    :param data: List of sequences (each sequence is a NumPy or CuPy array).\n","    :param max_len: The length to pad/truncate to. If None, uses the maximum length in data.\n","    :param padding_value: Value used for padding shorter sequences.\n","    :return: Padded sequences as a NumPy or CuPy array.\n","    \"\"\"\n","    # Determine the max length if not provided\n","    if max_len is None:\n","        max_len = max(len(seq) for seq in data)\n","\n","    print(f'maximum is : {max_len}')\n","\n","    # Create an empty padded array\n","    padded_data = np.full((len(data), max_len), padding_value, dtype=np.int16)\n","\n","    for i, seq in enumerate(data):\n","        seq = np.asarray(seq)  # Ensure compatibility with CuPy or NumPy\n","        truncated_seq = seq[:max_len]  # Truncate if longer than max_len\n","        padded_data[i, :len(truncated_seq)] = truncated_seq\n","\n","    return padded_data\n","\n","print(id_to_char[2])\n","\n","# Pad x_train, t_train, x_test, t_test\n","# x_train_padded = pad_sequences(x_train)\n","# t_train_padded = pad_sequences(t_train)\n","# x_test_padded = pad_sequences(x_test)\n","# t_test_padded = pad_sequences(t_test)\n","\n","# print(f\"x_train padded shape: {x_train_padded.shape}\")\n","# print(f\"t_train padded shape: {t_train_padded.shape}\")\n","# print(f\"x_test padded shape: {x_test_padded.shape}\")\n","# print(f\"t_test padded shape: {t_test_padded.shape}\")\n","\n","# # Reverse input sequences for training/testing\n","# x_train_padded = x_train_padded[:, ::-1]\n","# x_test_padded = x_test_padded[:, ::-1]\n","x1_train_padded = pad_sequences(x1_train)\n","# t1_train_padded = pad_sequences(t1_train)\n","x1_test_padded = pad_sequences(x1_test)\n","# t1_test_padded = pad_sequences(t1_test)\n","\n","print(f\"x_train padded shape: {x1_train_padded.shape}\")\n","# print(f\"t_train padded shape: {t1_train_padded.shape}\")\n","print(f\"x_test padded shape: {x1_test_padded.shape}\")\n","# print(f\"t_test padded shape: {t1_test_padded.shape}\")\n","\n","# Transfer data to GPU if enabled\n","if config.GPU:\n","    x_train_padded = to_gpu(x1_train_padded)\n","    t_train = to_gpu(t1_train)\n","    x_test_padded = to_gpu(x1_test_padded)\n","    t_test = to_gpu(t1_test)\n","\n","# Use padded data for training\n","x_train = x_train_padded\n","\n","x_test = x_test_padded\n","\n","# t = np.asnumpy(x_train[0])\n","# print(''.join(id_to_char[i] for i in t))\n","\n","\n","# 입력 문장 반전\n","x_train, x_test = x_train[:, ::-1], x_test[:, ::-1]\n","\n","# if config.GPU:\n","#     x_train = to_gpu(x_train)\n","#     x_test = to_gpu(x_test)\n","#     t_train = to_gpu(t_train)\n","#     t_test = to_gpu(t_test)\n","\n","# print(f'x_test len : {len(x_test)}')\n","# 하이퍼파라미터 설정\n","vocab_size = len(char_to_id)\n","wordvec_size = 5\n","hidden_size = 16\n","batch_size = 4096\n","max_epoch = 5\n","max_grad = 5.0\n","\n","output_size = 9\n","output_size2 = 1\n","\n","model = AttentionClassificationModel(vocab_size, wordvec_size, hidden_size, output_size, classification_type='multi-class')\n","model2 = AttentionClassificationModel(vocab_size, wordvec_size, hidden_size, output_size2) #binary\n","# model = AttentionSeq2seq(vocab_size, wordvec_size, hidden_size)\n","# model = Seq2seq(vocab_size, wordvec_size, hidden_size)\n","# model = PeekySeq2seq(vocab_size, wordvec_size, hidden_size)\n","\n","optimizer = Adam()\n","trainer = Trainer(model, optimizer)\n","trainer2=  Trainer(model2, optimizer) #danger\n","\n","acc_list = []\n","for epoch in range(max_epoch):\n","    trainer.fit(x_train, t_train, max_epoch=1,\n","                batch_size=batch_size, max_grad=max_grad)\n","\n","    # correct_num = 0\n","    # for i in range(len(x_test)):\n","    #     question, correct = x_test[[i]], t_test[[i]]\n","    #     verbose = i \u003c 10\n","    #     correct_num += eval_seq2seq(model, question, correct,\n","    #                                 id_to_char, verbose, is_reverse=True)\n","\n","    correct_num = 0\n","    chunk_size = 1000\n","    for start_idx in range(0, len(x_test), chunk_size):\n","        # Define the chunk range\n","        end_idx = min(start_idx + chunk_size, len(x_test))\n","        question_chunk = x_test[start_idx:end_idx]\n","        correct_chunk = t_test[start_idx:end_idx]\n","\n","        # Use eval_seq2seq_chunked for batch evaluation\n","        correct_num += eval_seq2seq_chunked(model, question_chunk, correct_chunk, id_to_char, verbose=(start_idx == 0), is_reverse=True)\n","\n","    acc = float(correct_num) / len(x_test)\n","    acc_list.append(acc)\n","    print('정확도 %.3f%%' % (acc * 100))\n","\n","\n","model.save_params()\n","\n","# 그래프 그리기\n","x = np.arange(len(acc_list))\n","if config.GPU:\n","    x = x.get()\n","plt.plot(x, acc_list, marker='o')\n","plt.xlabel('에폭')\n","plt.ylabel('정확도')\n","plt.ylim(-0.05, 1.05)\n","plt.show()\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"elapsed":39328,"status":"error","timestamp":1734005541395,"user":{"displayName":"seonghoon oh","userId":"01050507775812942445"},"user_tz":-540},"id":"hhq-JOzTkPRp","outputId":"a2f64eb1-2d2c-47b3-c6be-b28840ec8aa3"},"outputs":[{"ename":"AttributeError","evalue":"'list' object has no attribute 'astype'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-7-9d3f39874331\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 2\u003e\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx1_train_padded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----\u003e 2\u001b[0;31m \u001b[0mt1_train_padded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt1_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mx1_test_padded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx1_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mt1_test_padded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt1_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'astype'"]}],"source":["# coding: utf-8\n","import sys\n","from common import config\n","\n","# GPU execution setup\n","config.GPU = True\n","\n","import matplotlib.pyplot as plt\n","from common.optimizer import Adam\n","from common.trainer import Trainer\n","from common.util import to_gpu\n","from attentionclassifier import AttentionClassificationModel\n","from projectdataset.responseQAloader import ResponseQAloader\n","from projectdataset.preprocess import preprocess\n","\n","from common.np import *\n","\n","# Load dataset\n","loader = ResponseQAloader(base_path=\"projectdataset/responsedata\")\n","dataset = loader.load_data()\n","\n","# Preprocess dataset\n","a = preprocess()\n","trains, valids = a.preprocess_dataset(dataset, include_context=False)\n","\n","# Unpack datasets\n","gen_train = trains[0]\n","gen_val = valids[0]\n","class1_train = trains[1]\n","class1_val = valids[1]\n","class2_train = trains[2]\n","class2_val = valids[2]\n","\n","# Prepare classification datasets\n","x1_train = [x['input'] for x in class1_train]\n","t1_train = [x['output'] for x in class1_train]\n","x1_test = [x['input'] for x in class1_val]\n","t1_test = [x['output'] for x in class1_val]\n","\n","x2_train = [x['input'] for x in class2_train]\n","t2_train = [x['output'] for x in class2_train]\n","x2_test = [x['input'] for x in class2_val]\n","t2_test = [x['output'] for x in class2_val]\n","\n","# Pad sequences\n","def pad_sequences(data, max_len=None, padding_value=0):\n","    if max_len is None:\n","        max_len = max(len(seq) for seq in data)\n","    padded_data = np.full((len(data), max_len), padding_value, dtype=np.int16)\n","    for i, seq in enumerate(data):\n","        seq = np.asarray(seq)\n","        truncated_seq = seq[:max_len]\n","        padded_data[i, :len(truncated_seq)] = truncated_seq\n","    return padded_data\n","\n","x1_train_padded = pad_sequences(x1_train)\n","t1_train_padded = np.array(t1_train, dtype=np.int16)\n","x1_test_padded = pad_sequences(x1_test)\n","t1_test_padded = np.array(t1_test, dtype=np.int16)\n","\n","x2_train_padded = pad_sequences(x2_train)\n","t2_train_padded = np.array(t2_train, dtype=np.int16)\n","x2_test_padded = pad_sequences(x2_test)\n","t2_test_padded = np.array(t2_test, dtype=np.int16)\n","\n","# Transfer to GPU if enabled\n","if config.GPU:\n","    x1_train_padded = to_gpu(x1_train_padded)\n","    t1_train_padded = to_gpu(t1_train_padded)\n","    x1_test_padded = to_gpu(x1_test_padded)\n","    t1_test_padded = to_gpu(t1_test_padded)\n","\n","    # x2_train_padded = to_gpu(x2_train_padded)\n","    # t2_train_padded = to_gpu(t2_train_padded)\n","    # x2_test_padded = to_gpu(x2_test_padded)\n","    # t2_test_padded = to_gpu(t2_test_padded)\n","\n","# Hyperparameters\n","vocab_size = len(a.get_vocab()[0])\n","wordvec_size = 5\n","hidden_size = 16\n","batch_size = 4096\n","max_epoch = 5\n","max_grad = 5.0\n","output_size1 = 9\n","output_size2 = 1\n","\n","# Initialize models\n","model1 = AttentionClassificationModel(vocab_size, wordvec_size, hidden_size, output_size1, classification_type='multi-label')\n","model2 = AttentionClassificationModel(vocab_size, wordvec_size, hidden_size, output_size2, classification_type='binary')\n","\n","optimizer1 = Adam()\n","optimizer2 = Adam()\n","\n","trainer1 = Trainer(model1, optimizer1)\n","trainer2 = Trainer(model2, optimizer2)\n","\n","# Training loop\n","for epoch in range(max_epoch):\n","    print(f\"Epoch {epoch + 1}/{max_epoch} for Classification 1\")\n","    trainer1.fit(x1_train_padded, t1_train_padded, max_epoch=1, batch_size=batch_size, max_grad=max_grad)\n","\n","    # print(f\"Epoch {epoch + 1}/{max_epoch} for Classification 2\")\n","    # trainer2.fit(x2_train_padded, t2_train_padded, max_epoch=1, batch_size=batch_size, max_grad=max_grad)\n","\n","    # Evaluate Classification 1\n","    preds1 = model1.generate(x1_test_padded)\n","    preds1 = (preds1 \u003e= 0.5).astype(int)  # Threshold for multi-label classification\n","    acc1 = (preds1 == t1_test_padded).mean()\n","    print(f\"Classification 1 Accuracy: {acc1 * 100:.2f}%\")\n","\n","    # Evaluate Classification 2\n","    # preds2 = model2.forward(x2_test_padded)\n","    # preds2 = (preds2 \u003e= 0.5).astype(int)  # Threshold for binary classification\n","    # acc2 = (preds2 == t2_test_padded).mean()\n","    # print(f\"Classification 2 Accuracy: {acc2 * 100:.2f}%\")\n","\n","# Save models\n","model1.save_params(\"classification1_params.pkl\")\n","# model2.save_params(\"classification2_params.pkl\")\n","\n","# Visualization\n","plt.plot(trainer1.loss_list, label='Classification 1 Loss')\n","# plt.plot(trainer2.loss_list, label='Classification 2 Loss')\n","plt.xlabel('Iterations')\n","plt.ylabel('Loss')\n","plt.legend()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_brzthsEkQNp"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}